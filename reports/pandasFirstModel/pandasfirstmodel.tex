\documentclass[12pt,a4paper]{article}

% Package to include code
\usepackage{listings}
\usepackage{color}
\lstset{language=Python}
\lstset{numbers=none, basicstyle=\footnotesize\ttfamily,
  numberstyle=\tiny,keywordstyle=\color{blue},stringstyle=\ttfamily,showstringspaces=false}
\lstset{backgroundcolor=\color[rgb]{0.95 0.95 0.95}}
%\lstdefinestyle{numbers}{numbers=left, stepnumber=1, numberstyle=\tiny, numbersep=10pt,basicstyle=\footnotesize\ttfamily}
\lstdefinestyle{numbers}{numbers=left}
\lstdefinestyle{nonumbers}{numbers=none,basicstyle=\footnotesize\ttfamily}
%\lstdefinestyle{nonumbers}{numbers=none}
%\lstdefinestyle{tiny}{numbers=none,basicstyle=\tiny\ttfamily}

% Font selection: uncomment the next line to use the ``beton'' font
%\usepackage{beton}

% Font selection: uncomment the next line to use the ``times'' font
%\usepackage{times}

% Font for equations
\usepackage{euler}


%Package to define the headers and footers of the pages
\usepackage{fancyhdr}


%Package to include an index
\usepackage{index}

%Package to display boxes around texts. Used especially for the internal notes.
\usepackage{framed}

%PSTricks is a collection of PostScript-based TEX macros that is compatible
% with most TEX macro packages
\usepackage{pstricks}
\usepackage{pst-node}
\usepackage{pst-plot}
\usepackage{pst-tree}

% To include hyperlinks in the PDF file
\usepackage{hyperref}

%Package to display boxes around a minipage. Used especially to
%describe the biography of people.
\usepackage{boxedminipage}

%Package to include postscript figures
\usepackage{epsfig}

%Package for the bibliography
% \cite{XXX} produces Ben-Akiva et. al., 2010
% \citeasnoun{XXX} produces Ben-Akiva et al. (2010)
% \citeasnoun*{XXX} produces Ben-Akiva, Bierlaire, Bolduc and Walker (2010)
\usepackage[dcucite,abbr]{harvard}
\harvardparenthesis{none}\harvardyearparenthesis{round}

%Packages for advanced mathematics typesetting
\usepackage{amsmath,amsfonts,amssymb}

%Package to display trees easily
%\usepackage{xyling}

%Package to include smart references (on the next page, on the
%previous page, etc.) 
%%

%% Remove as it is not working when the book will be procesed by the
%% publisher.
%\usepackage{varioref}

%Package to display the euro sign
\usepackage[right,official]{eurosym}

%Rotate material, especially large table (defines sidewaystable)
\usepackage[figuresright]{rotating}

%Defines the subfigure environment, to obtain refs like Figure 1(a)
%and Figure 1(b). 
\usepackage{subfigure}

%Package for appendices. Allows subappendices, in particular
\usepackage{appendix}

%Package controling the fonts for the captions
\usepackage[font={small,sf}]{caption}

%Defines new types of columns for tabular ewnvironment
\usepackage{dcolumn}
\newcolumntype{d}{D{.}{.}{-1}}
\newcolumntype{P}[1]{>{#1\hspace{0pt}\arraybackslash}}
\newcolumntype{.}{D{.}{.}{9.3}}

%Allows multi-row cells in tables
\usepackage{multirow}

%Tables spaning more than one page
\usepackage{longtable}


%%
%%  Macros by Michel
%%

%Internal notes
\newcommand{\note}[1]{
\begin{framed}{}%
\textbf{\underline{Internal note}:} #1
\end{framed}}

%Use this version to turn off the notes
%\newcommand{\note}[1]{}


%Include a postscript figure . Note that the label is prefixed with
%``fig:''. Remember it when you refer to it.  
%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\afigure}[3]{%
\begin{figure}[!tbp]%
\begin{center}%
\epsfig{figure=#2,width=0.8\textwidth}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{figure}}






%Include two postscript figures side by side. 
% #1 label of the first figure
% #2 file for the first figure
% #3 Caption for the first figure
% #4 label of the second figure
% #5 file for the second figure
% #6 Caption for the first figure
% #7 Caption for the set of two figures
\newcommand{\twofigures}[7]{%
\begin{figure}[htb]%
\begin{center}%
\subfigure[\label{fig:#1}#3]{\epsfig{figure=#2,width=0.45\textwidth}}%
\hfill
\subfigure[\label{fig:#4}#6]{\epsfig{figure=#5,width=0.45\textwidth}}%
\end{center}
\caption{#7}%
\end{figure}}

%Include a figure generated by gnuplot using the epslatex output. Note that the label is prefixed with
%``fig:''. Remember it when you refer to it.  
 
%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\agnuplotfigure}[3]{%
\begin{figure}[!tbp]%
\begin{center}%
\input{#2}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{figure}}

%Three arguments:
% #1 label
% #2 file (without extension)
% #3 Caption
\newcommand{\asidewaysgnuplotfigure}[3]{%
\begin{sidewaysfigure}[!tbp]%
\begin{center}%
\input{#2}%
\end{center}
\caption{\label{fig:#1} #3}%
\end{sidewaysfigure}}


%Include two postscript figures side by side. 
% #1 label of the first figure
% #2 file for the first figure
% #3 Caption for the first figure
% #4 label of the second figure
% #5 file for the second figure
% #6 Caption for the second figure
% #7 Caption for the set of two figures
% #8 label for the whole figure
\newcommand{\twognuplotfigures}[7]{%
\begin{figure}[htb]%
\begin{center}%
\subfigure[\label{fig:#1}#3]{\input{#2}}%
\hfill
\subfigure[\label{fig:#4}#6]{\input{#5}}%
\end{center}
\caption{#7}%
\end{figure}}



%Include the description of somebody. Four arguments:
% #1 label
% #2 Name
% #3 file (without extension)
% #4 description
\newcommand{\people}[4]{
\begin{figure}[tbf]
\begin{boxedminipage}{\textwidth}
\parbox{0.40\textwidth}{\epsfig{figure=#3,width = 0.39\textwidth}}%\hfill
\parbox{0.59\textwidth}{%
#4% 
}%
\end{boxedminipage}
\caption{\label{fig:#1} #2}
\end{figure}
}

%Default command for a definition
% #1 label (prefix def:)
% #2 concept to be defined
% #3 definition
\newtheorem{definition}{Definition}
\newcommand{\mydef}[3]{%
\begin{definition}%
\index{#2|textbf}%
\label{def:#1}%
\textbf{#2} \slshape #3\end{definition}}

%Reference to a definitoin. Prefix 'def:' is assumed
\newcommand{\refdef}[1]{definition~\ref{def:#1}}


%Default command for a theorem, with proof
% #1: label (prefix thm:)
% #2: name of the theorem
% #3: statement
% #4: proof
\newtheorem{theorem}{Theorem}
\newcommand{\mytheorem}[4]{%
\begin{theorem}%
\index{#2|textbf}%
\index{Theorems!#2}%
\label{thm:#1}%
\textbf{#2} \sffamily \slshape #3
\end{theorem} \bpr #4 \epr \par}


%Default command for a theorem, without proof
% #1: label (prefix thm:)
% #2: name of the theorem
% #3: statement
\newcommand{\mytheoremsp}[3]{%
\begin{theorem}%
\index{#2|textbf}%
\index{Theorems!#2}%
\label{thm:#1}%
\textbf{#2} \sffamily \slshape #3
\end{theorem}}



%Put parentheses around the reference, as standard for equations
\newcommand{\req}[1]{(\ref{#1})}

%Short cut to make a column vector in math environment (centered)
\newcommand{\cvect}[1]{\left( \begin{array}{c} #1 \end{array} \right) }

%Short cut to make a column vector in math environment (right justified)
\newcommand{\rvect}[1]{\left( \begin{array}{r} #1 \end{array} \right) }

%A reference to a theorem. Prefix thm: is assumed for the label.
\newcommand{\refthm}[1]{theorem~\ref{thm:#1}}

%Reference to a figure. Prefix fig: is assumed for the label.
\newcommand{\reffig}[1]{Figure~\ref{fig:#1}}

%Smart reference to a figure. Prefix fig: is assumed for the label.
%\newcommand{\vreffig}[1]{Figure~\vref{fig:#1}}

%C in mathcal font for the choice set
\newcommand{\C}{\mathcal{C}}

%R in bold font for the set of real numbers
\newcommand{\R}{\mathbb{R}}

%N in bold font for the set of natural numbers
\newcommand{\N}{\mathbb{N}}

%C in mathcal font for the log likelihood
\renewcommand{\L}{\mathcal{L}}

%S in mathcal font for the subset S
\renewcommand{\S}{\mathcal{S}}

%To write an half in math envionment
\newcommand{\half}{\frac{1}{2}}

%Probability
\newcommand{\prob}{\operatorname{Pr}}

%Expectation
\newcommand{\expect}{\operatorname{E}}

%Variance
\newcommand{\var}{\operatorname{Var}}

%Covariance
\newcommand{\cov}{\operatorname{Cov}}

%Correlation
\newcommand{\corr}{\operatorname{Corr}}

%Span
\newcommand{\myspan}{\operatorname{span}}

%plim
\newcommand{\plim}{\operatorname{plim}}

%Displays n in bold (for the normal distribution?)
\newcommand{\n}{{\bf n}}

%Includes footnote in a table environment. Warning: the footmark is
%always 1.
\newcommand{\tablefootnote}[1]{\begin{flushright}
\rule{5cm}{1pt}\\
\footnotemark[1]{\footnotesize #1}
\end{flushright}
}

%Defines the ``th'' as in ``19th'' to be a superscript
\renewcommand{\th}{\textsuperscript{th}}

%Begin and end of a proof
\newcommand{\bpr}{{\bf Proof.} \hspace{1 em}}
\newcommand{\epr}{$\Box$}


\title{A short introduction to \PDBIOGEME}
\author{Michel Bierlaire} 
\date{\today}

\newcommand{\PBIOGEME}{PythonBiogeme}
\newcommand{\PDBIOGEME}{PandasBiogeme}
\newcommand{\BIOGEME}{Biogeme}
\newcommand{\BBIOGEME}{BisonBiogeme}

\newcommand*{\examplesPath}{../examples}
\begin{document}


\begin{titlepage}
\pagestyle{empty}

\maketitle
\vspace{2cm}

\begin{center}
\small Report TRANSP-OR 200605 \\ Transport and Mobility Laboratory \\ School of Architecture, Civil and Environmental Engineering \\ Ecole Polytechnique F\'ed\'erale de Lausanne \\ \verb+transp-or.epfl.ch+
\begin{center}
\textsc{Series on Biogeme}
\end{center}

\emph{This is an updated version of \citeasnoun{Bier18}, adapted for
  Biogeme 3.2.6.}
\end{center}


\clearpage
\end{titlepage}


The package Biogeme (\texttt{biogeme.epfl.ch}) is designed to estimate the parameters of
various models using maximum likelihood estimation. It is particularly
designed for discrete choice models. In this document, we present step
by step how to specify a simple model, estimate its parameters and
interpret the output of the  package.  We assume that the
reader is already familiar with discrete choice models (\cite{BenALerm85}), and has
successfully installed \PDBIOGEME. Note that \PBIOGEME\ and \PDBIOGEME\
have a very similar syntax. The difference is that \PBIOGEME\ is an
independent software package written in C++, and using the Python
language for model specification.



\PDBIOGEME\ is a genuine Python
package written in Python and C++, that relies on the Pandas library
for the management of the data. This is the standard mode of operations of more and more
data scientists. The syntax for model specification is
almost identical, but there are slight differences, that are
highlighted at the end of the document.  This document has been written using
\PDBIOGEME\ 3.2.6, but should remain valid for future versions.  

\section{Data}

Biogeme assumes that a Pandas database is available, containing only numerical
entries. Each column corresponds to a variable, each row to an
observation.

If you are not familiar with Pandas, prepare a file that contains in its first line a list
of labels corresponding to the available data, and that each
subsequent line contains the exact same number of numerical data, each
row corresponding to an observation. Delimiters can be tabs or
spaces. 


The data file used for this example is \texttt{swissmetro.dat}. It can
be downloaded from the ``Data'' section of \href{http://biogeme.epfl.ch}{biogeme.epfl.ch}.



\section{Python}

\PDBIOGEME\ is a package of the Python programming
language. Therefore, estimating a model amounts to writing a script in
 Python. Online tutorials and  documentation about Python can easily be found. Although it
is not necessary to master the Python language to specify models for
Biogeme, it would definitely help to learn at least the basics. In
this Section, we report some useful information when using the package
Biogeme.
\begin{itemize}
\item Two versions of Python are commonly used: 2 and 3. Biogeme works only
  with Python version 3.
 \item Python is available on Linux, MacOSX and
   Windows. \PDBIOGEME\ is platform independent. 
\item The syntax of Python is case sensitive. It means that
\verb+varname+ and \verb+Varname+, for instance, would represent two
different entities.
\item The indentation of the code is important in Python. It is
  advised to use a text editor that has a ``Python mode'' to help
  managing these indentations.
 \item A Python statement must be on a single line. Sometimes, for the
   sake of readability, it is convenient to split the statement on
   several lines. In that case, the character \lstinline+\+ must be
   inserted at the end of a line to inform Python that the statement
   continues at the following line. There are several examples below,
   for instance in the specification of the utility functions.
\end{itemize}

\section{The model}
The model is a logit model with 3 alternatives: \emph{train}, \emph{Swissmetro} and \emph{car}. The utility functions are defined as:
\begin{lstlisting}[style=nonumbers,backgroundcolor=]
V1 = ASC_TRAIN + \
     B_TIME * TRAIN_TT_SCALED + \
     B_COST * TRAIN_COST_SCALED
V2 = ASC_SM + \
     B_TIME * SM_TT_SCALED + \
     B_COST * SM_COST_SCALED
V3 = ASC_CAR + \
     B_TIME * CAR_TT_SCALED + \
     B_COST * CAR_CO_SCALED
\end{lstlisting}
where
\begin{itemize}
\item \lstinline@TRAIN_TT_SCALED@,
\item \lstinline@TRAIN_COST_SCALED@,
\item \lstinline@SM_TT_SCALED@,
\item \lstinline@SM_COST_SCALED@,
\item \lstinline@CAR_TT_SCALED@,
\item \lstinline@CAR_CO_SCALED@
\end{itemize}
are variables, and
\begin{itemize}
\item   \lstinline@ASC_TRAIN@,
\item   \lstinline@ASC_SM@,
\item   \lstinline@ASC_CAR@,
\item   \lstinline@B_TIME@,
\item   \lstinline@B_COST@
\end{itemize}
  are parameters to be estimated. Note that it is not possible to identify all alternative specific constants  
  \lstinline@ASC_TRAIN@,
  \lstinline@ASC_SM@,
  \lstinline@ASC_CAR@ from data. Consequently,  \lstinline@ASC_SM@
  is normalized to 0. 

The availability of an alternative \texttt{i} is determined by the
variable $y_i$, \texttt{i}=1, 2, 3, which is equal to 1 if the
alternative is available, and 0 otherwise. The probability of choosing an
available alternative \texttt{i} is given by the logit model: 
\begin{equation}
P(i|\{1,2,3\};x,\beta) = \frac{y_i e^{V_i(x,\beta)}}{y_1 e^{V_1(x,\beta)} + y_2 e^{V_2(x,\beta)}+ y_3 e^{V_3(x,\beta)}}.
\end{equation}
Given a data set of $N$ observations, the log likelihood of the
sample is 
\begin{equation}
\L = \sum_n \log P(i_n|\{1,2,3\};x_n,\beta)
\end{equation}
where $i_n$ is the alternative actually chosen
by individual $n$, and $x_n$ are the explanatory variables associated with
individual $n$.  

\section{Model specification: \PDBIOGEME}
\label{sec:mod}

The model specification file must have an extension \lstinline$.py$. 
The file \lstinline$01logit.py$ is reported in
Section~\ref{sec:modelPython}. We describe here its content. 

The objective is to provide to \PDBIOGEME\ the formula of the log
likelihood function to maximize, using a syntax based on the Python
programming language, and extended for the specific needs of \BIOGEME.
The file can
contain comments, designed to document the specification.
Single-line comments are included using the characters \verb+#+, consistently with
the Python syntax. All characters
after this command, up to the end of the current line, are ignored by
Python.
Multiple lines comments  are created by adding a delimiter
(\verb+"""+) at the beginning and the end  of the comment.
In our example, the file starts with comments describing the name of
the file, its author and the date when it was created. A short
description of its content is also provided. 
\begin{lstlisting}[style=nonumbers]
"""File 01logit.py

:author: Michel Bierlaire, EPFL
:date: Thu Sep  6 15:14:39 2018

 Example of a logit model.
 Three alternatives: Train, Car and Swissmetro
 SP data
"""
\end{lstlisting}
These comments are
completely ignored by Python. However, it is recommended to use
many comments to describe the model specification, for future
reference, or to help other persons to understand the specification. 

The specification file must start by loading the Python libraries
needed by \PDBIOGEME. The following libraries must be loaded:
\begin{itemize}
\item \lstinline+pandas+, the generic package for data management,
\item \lstinline+biogeme.database+, the Biogeme module for data management,
\item \lstinline+biogeme.biogeme+, the core Biogeme module,
\item \lstinline+biogeme.models+, the Biogeme module for choice models.
\end{itemize}
It is custom in Python to use shortcuts to simplify the syntax. Here,
we use \lstinline+pd+,  \lstinline+db+,   \lstinline+bio+, and   \lstinline+models+,
respectively.   Finally, we need to import the expressions to build
the model specification. In this example, we use only the expression
\lstinline+Beta+ that defines parameters to be estimated.
 
\begin{lstlisting}[style=nonumbers]
import pandas as pd
import biogeme.database as db
import biogeme.biogeme as bio
import biogeme.models as models
from biogeme.expressions import Beta
\end{lstlisting}

The next step consists in preparing the Pandas database. If you have
a data file formatted for previous versions of Biogeme,   this can easily be done using the
following statements:
\begin{lstlisting}[style=nonumbers]
df = pd.read_csv('swissmetro.dat', '\t')
database = db.Database('swissmetro', df)
\end{lstlisting}
The first statement reads the data from the file, using tabs as
delimiters. It stores it in a
Pandas data structure. The second statement prepares the database for
Biogeme. 
Clearly, if you prefer to create your Pandas database in another way,
it is possible. In that case, you still have to use the second statement to
transfer the Pandas database to Biogeme. 

The name of the columns in the database characterize the variables for
your model. In order to make them available as a Python variable, the
following statement must be included: 
\begin{lstlisting}[style=nonumbers]
globals().update(database.variables)
\end{lstlisting}

It is possible to tell \PDBIOGEME\ to ignore some
observations in the data file. A boolean expression must be defined, that
is evaluated for each observation in the data file.  Each observation
such that this expression is ``true'' is discarded from the
sample. In our example, the modeler has developed the model only for
work trips, so that every observation such that the trip purpose is not 1
or 3 is removed.

Observations such that the dependent variable \lstinline$CHOICE$ is 0 are also
removed. The convention is that ``false'' is represented by 0,
and ``true'' by 1, so that the `*' can be interpreted as a ``and'',
and the `+' as a ``or''. Note also that the result of the `+' can be
2, so that we test if the result is equal to 0 or not. The exclude condition in our example is
therefore interpreted as: either (\lstinline$PURPOSE$ different from 1
and \lstinline$PURPOSE$ different from 3), or \lstinline$CHOICE$ equal
to 0. 

\begin{lstlisting}[style=nonumbers]
exclude = ((PURPOSE != 1) * (PURPOSE != 3) + (CHOICE == 0)) > 0
database.remove(exclude)
\end{lstlisting}

\begin{itemize}
\item We have conveniently used an intermediary Python variable
\lstinline+exclude+ in this example. It is not necessary. The above
statement is completely equivalent to 
\begin{lstlisting}[style=nonumbers]
database.remove((( PURPOSE != 1 ) * (  PURPOSE   !=  3  ) +\
                 ( CHOICE == 0 )) > 0)
\end{lstlisting}
\item The same result can be obtained using Pandas
directly, using the following syntax:
\begin{lstlisting}[style=nonumbers]
remove = (((database.data.PURPOSE != 1) & \
           (database.data.PURPOSE != 3)) | \
           (database.data.CHOICE == 0))
database.data.drop(database.data[remove].index,inplace=True)
\end{lstlisting}
Pandas provides more powerful tools to manage the database. If you
need to perform sophisticated data manipulations, it is advised to use
Pandas instead of Biogeme for these purposes. Refer to the online
Pandas documentation and the many tutorials available online. 
\end{itemize}

The next statements use the function \lstinline+Beta+ to define the parameters to be estimated. For each parameter, the following information must be mentioned:
\begin{enumerate}
\item the name of the parameter,
\item the default value,
\item a lower bound (or \lstinline+None+, if no bound is specified),
\item an upper bound, (or \lstinline+None+, if no bound is specified),
\item a flag that indicates if the parameter must be estimated (0) or
  if it keeps its default value (1).
\end{enumerate}

\begin{lstlisting}[style=nonumbers]
ASC_CAR = Beta('ASC_CAR',0,None,None,0)
ASC_TRAIN = Beta('ASC_TRAIN',0,None,None,0)
ASC_SM = Beta('ASC_SM',0,None,None,1)
B_TIME = Beta('B_TIME',0,None,None,0)
B_COST = Beta('B_COST',0,None,None,0)
\end{lstlisting}

\begin{itemize}
\item  In Python, case sensitivity is enforced, so that
\verb+varname+ and \verb+Varname+ would represent two different
variables.  In our example, the default value of each parameter is
0. If a previous estimation had been performed before, we could have
used the previous estimates as default value.
\item For the
parameters that are estimated by \PDBIOGEME, the default value is used
as the starting value for the optimization algorithm. For the
parameters that are not estimated, the default value is used
throughout the estimation process. In our example, the parameter
\lstinline$ASC_SM$ is not estimated (as specified by the \lstinline$1$
in the fifth argument on the corresponding line), and its value is
fixed to \lstinline$0$.
\item 
A lower bound and an upper bound must be
specified. If no bound is meaningful,  use \lstinline$None$.
\item Nothing
prevents to write
\begin{lstlisting}[style=nonumbers]
car_cte = Beta('ASC_CAR',0,None, None,0)
\end{lstlisting}
and to use \lstinline+car_cte+ later in the specification.   We
\textbf{strongly} advise against this practice, and suggest to use the
exact same name for the Python variable on the left hand side, and for
the \PDBIOGEME\ variable, appearing as the first argument of the
function, as illustrated in this example. 
\end{itemize}

It is possible to define new variables in addition to the variables
defined in the data files. 
\begin{lstlisting}[style=nonumbers]
SM_COST = SM_CO * (GA == 0)
TRAIN_COST = TRAIN_CO * (GA == 0)
CAR_AV_SP = CAR_AV * (SP != 0)
TRAIN_AV_SP = TRAIN_AV * (SP != 0)
\end{lstlisting}

When boolean expressions are involved, the value True is
  represented by 1, and the value False is represented by
  0. Therefore, a multiplication involving a boolean expression is
  equivalent to a ``and'' operator. The above code is interpreted in
  the following way:
\begin{itemize}
\item \lstinline$CAR_AV_SP$ is equal to \lstinline$CAR_AV$ if
  \lstinline$SP$ is different from 0, and is equal to 0
  otherwise. \lstinline$TRAIN_AV_SP$ is defined similarly.
\item \lstinline$SM_COST$ is equal to \lstinline$SM_CO$ if
  \lstinline$GA$ is equal to 0, that is, if the traveler does not have
  a yearly pass (called ``general abonment''). If the traveler
  possesses a yearly pass, then \lstinline$GA$ is different from 0,
  and the variable \lstinline$SM_COST$ is zero. The variable
  \lstinline$TRAIN_COST$ is defined in the same way.
\end{itemize}

Variables can be also be rescaled. For numerical reasons, it is good
practice to scale the data so that the values of the estimated parameters are around 1. A previous estimation with the unscaled data has generated
parameters around -0.01 for both cost and time. Therefore, 
time and cost are divided by 100.

\begin{lstlisting}[style=nonumbers]
TRAIN_TT_SCALED = TRAIN_TT / 100
TRAIN_COST_SCALED = TRAIN_COST / 100
SM_TT_SCALED = SM_TT / 100
SM_COST_SCALED = SM_COST / 100
CAR_TT_SCALED = CAR_TT / 100
CAR_CO_SCALED = CAR_CO / 100
\end{lstlisting}

We now write the specification of the
utility functions. 

\begin{lstlisting}[style=nonumbers]
V1 = ASC_TRAIN + \
     B_TIME * TRAIN_TT_SCALED + \
     B_COST * TRAIN_COST_SCALED
V2 = ASC_SM + \
     B_TIME * SM_TT_SCALED + \
     B_COST * SM_COST_SCALED
V3 = ASC_CAR + \
     B_TIME * CAR_TT_SCALED + \
     B_COST * CAR_CO_SCALED
\end{lstlisting}

We need to associate each utility function with the number, the identifier, of the
alternative, using the same numbering convention as in the data file. In this
example, the convention is described in Table~\ref{tab:choice}.

\begin{table}[htb]
\begin{center}
\begin{tabular}{rl}
Train & 1 \\
Swissmetro & 2 \\
Car & 3
\end{tabular}
\end{center}
\caption{\label{tab:choice}Numbering of the alternatives}
\end{table}


To do
this, we use a Python dictionary:
\begin{lstlisting}[style=nonumbers]
V = {1: V1,
     2: V2,
     3: V3}
\end{lstlisting}
We use also a dictionary to describe the availability conditions of
each alternative:
\begin{lstlisting}[style=nonumbers]
av = {1: TRAIN_AV_SP,
      2: SM_AV,
      3: CAR_AV_SP}
\end{lstlisting}


We now define the choice model. The function \lstinline+models.loglogit+
provides the logarithm of the choice probability of the logit
model. It takes three arguments: 
\begin{enumerate}
\item the dictionary describing the utility functions,
\item the dictionary describing the availability conditions,
\item the alternative for which the probability must be calculated.
\end{enumerate}
In this example, we obtain
\begin{lstlisting}[style=nonumbers]
logprob = models.loglogit(V, av, CHOICE)
\end{lstlisting}

We are now ready to create the \lstinline+BIOGEME+ object, using the
following syntax:
\begin{lstlisting}
biogeme = bio.BIOGEME(database, logprob)
\end{lstlisting}
The constructor accepts two mandatory arguments:
\begin{itemize}
\item the database object containing the data,
\item the formula for the contribution to the log likelihood of each
  row in the database. 
\end{itemize}
It is advised to give a name to the model using the following
statement:
\begin{lstlisting}
biogeme.modelName = '01logit'
\end{lstlisting}

The estimation of the model parameters is performed using the
following statement. 

\begin{lstlisting}
results = biogeme.estimate()
\end{lstlisting}


\section{Running \PDBIOGEME}

The script is executed like any python script. Typically, by typing
\begin{lstlisting}
python 01logit.py
\end{lstlisting}
is a terminal, or by typing ``shift-return'' in a Jupyter notebook.

By default, running \PDBIOGEME\ is silent, in the sense that it does
not produce any output. 
Two files are generated:
\begin{itemize}
\item \lstinline+01logit.html+ reports the results of the estimation
  is HTML format, and can be opened in your favorite browser. 
\item \lstinline+01logit.pickle+ is a snapshot of the results of the
estimation, and can be used in another Python script. 
\end{itemize}

In order to avoid erasing previously generated results, the name of
the files may vary from one run to the next. Therefore,
it is important to verify the latest files created in the directory. 

You can also print the name of the files that were actually
created using the following Python statement:
\begin{lstlisting}
print(f'HTML file:   {results.data.htmlFileName}')
print(f'Pickle file: {results.data.pickleFileName}')
\end{lstlisting}
\clearpage

\section{\PDBIOGEME: the report file}
\label{sec:pythonreport}

The report file generated by \PDBIOGEME\ gathers information
about the result of the estimation. First, some information about the
version of Biogeme, and some links to relevant URLs is provided. 
Next, the name of the report file and the name of the database  are reported. 

The estimation report follows, including
   \begin{itemize}
      \item The number of parameters that have been estimated.
      \item The sample size, that is, the number of rows in
        the data file  that have not been excluded.
      \item The number of excluded observations.
      \item \texttt{Init log likelihood} is the log likelihood
        $\mathcal{L}^i$ of
        the sample for the model defined with the default values of
        the parameters. 
      \item \texttt{Final log likelihood} is the log likelihood
        $\mathcal{L}^*$ of the sample for the estimated model. 
      \item \texttt{Likelihood ratio test for the init. model} is 
         \begin{equation}
            -2 ( \mathcal{L}^i - \mathcal{L}^*)
         \end{equation}
         where 
         $ \mathcal{L}^i$ is the log likelihood of the init model
         as defined above, and $\mathcal{L}^*$ is the log likelihood of the sample for the estimated model. 
      \item \texttt{Rho-square for the init. model} is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^*}{\mathcal{L}^i}.
         \end{equation}
        \item \texttt{Rho-square-bar for the init. model} is
         \begin{equation}
            \rho^2 = 1 - \frac{\mathcal{L}^* - K}{\mathcal{L}^i}.
         \end{equation}
         where $K$ is the number of estimated parameters.
       \item \texttt{Akaike Information Criterion} is:
         \begin{equation}
          2 K - 2 \mathcal{L}^*,
         \end{equation}
         where $K$ is the number of estimated parameters.
       \item \texttt{Bayesian Information Criterion} is:
         \begin{equation}
 - 2 \mathcal{L}^* + K \ln(N),
         \end{equation}
         where  $K$ is the number of estimated parameters, and $N$ is
         the sample size. 
      \item \texttt{Final gradient norm} is the gradient of the log
        likelihood function computed for the estimated parameters.
      \item \texttt{Nbr of threads} is the number of processors used
        by Biogeme to calculate the log likelihood at each iteration.
       \item \texttt{Algorithm} is the optimization algorithm used to
         solve the maximum likelihood estimation problem.
        \item \texttt{Proportion analytical hessian} is the proportion
          of iterations where the analytical second derivatives matrix
          (called ``hessian'') has been calculated.
         \item \texttt{Relative projected gradient} is the norm of the
           projected gradient, scaled to account for the level of
           magnitude of the log likelihood. This quantity is used as
           stopping criterion for the algorithm.
         \item \texttt{Number of iterations} is the number of
           iterations performed by the optimization algorithms.
         \item \texttt{Number of function evaluations} reports the
           number of times that the log likelihood function has been
           calculated.
         \item \texttt{Number of gradient evaluations} reports the
           number of times that the gradient of the log likelihood function has been
           calculated.
         \item \texttt{Number of hessian evaluations} reports the
           number of times that the second derivatives matrix (or
           hessian) of the log likelihood function has been
           calculated.
         \item \texttt{Cause of termination} provides the reason why
           the optimization algorithm has stopped. 
         \item \texttt{Optimization time} is the actual time used by the algorithm.
   \end{itemize}


The following section reports the estimates of the parameters of the
utility function,
together with some statistics. For each parameter $\beta_k$, the following is reported:
   \begin{itemize}
  \item The name of the parameter.
      \item The estimated value $\beta_k$. 
      \item The standard error $\sigma_k$ of the estimate, calculated as the
         square root of the $k$\th diagonal entry of the
         Rao-Cramer bound (see Appendix~\ref{sec:robust}).
     \item The $t$ statistics, calculated as $t_k=\beta_k/\sigma_k$.
     \item The $p$ value, calculated as $2 (1 - \Phi(t_k))$,
where $\Phi(\cdot)$ is the cumulative distribution function of the
univariate standard normal distribution. 
      \item The robust standard error $\sigma^R_k$ of the estimate, calculated as the
         square root of the $k$\th diagonal entry of the
         robust estimate of the variance covariance matrix. (see Appendix~\ref{sec:robust}).
     \item The robust $t$ statistics, calculated as $t^R_k=\beta_k/\sigma^R_k$.
     \item The robust $p$ value, calculated as $2 (1 - \Phi(t^R_k))$,
where $\Phi(\cdot)$ is the cumulative density function of the
univariate normal distribution. 
   \end{itemize}

The last section reports, for each pair of parameters $k$ and
$\ell$,
\begin{itemize}
\item the name of $\beta_k$,
\item the name of $\beta_\ell$,
\item the entry $\Sigma_{k,\ell}$ of the 
         Rao-Cramer bound (see Appendix~\ref{sec:robust}),
\item the correlation between $\beta_k$ and $\beta_\ell$, calculated as
\begin{equation}
\frac{\Sigma_{k,\ell}}{\sqrt{\Sigma_{k,k}\Sigma_{\ell,\ell}}},
\end{equation}
\item the $t$ statistics, calculated as
\begin{equation}
t_{k,\ell}= \frac{\beta_k - \beta_\ell}{\sqrt{\Sigma_{k,k} + \Sigma_{\ell,\ell} - 2 \Sigma_{k,\ell}}},
\end{equation}
  \item the $p$ value, calculated as $2 (1 - \Phi(t_{k,\ell}))$,
where $\Phi(\cdot)$ is the cumulative density function of the
univariate standard normal distribution,
\item the entry $\Sigma^R_{k,\ell}$ of $\Sigma^R$, the robust estimate of the variance covariance matrix (see Appendix~\ref{sec:robust}),
\item the robust correlation between $\beta_k$ and $\beta_\ell$, calculated as
\begin{equation}
\frac{\Sigma^R_{k,\ell}}{\sqrt{\Sigma^R_{k,k}\Sigma^R_{\ell,\ell}}},
\end{equation}
\item the robust $t$ statistics, calculated as
\begin{equation}
t^R_{k,\ell}=\frac{\beta_k - \beta_\ell}{\sqrt{\Sigma^R_{k,k} + \Sigma^R_{\ell,\ell}
    - 2 \Sigma^R_{k,\ell}}},
\end{equation}
     \item the robust $p$ value, calculated as $2 (1 - \Phi(t^R_{k,\ell}))$,
where $\Phi(\cdot)$ is the cumulative density function of the
univariate standard normal distribution,
\end{itemize}
The final lines report the value of the smallest and the largest
eigenvalues, as well as the ratio between the two, called the
``condition number''.   If smallest eigenvalue is close to zero, it is a sign of
singularity, that may be due to a lack of variation in the data or
an unidentified model.


\section{The results as Python variables}

The estimation function returns an object that contains the results of
the estimation as well as the associated statistics. This object can
be printed on screen:
\begin{lstlisting}[style=nonumbers]
print("Results=",results)
\end{lstlisting}

If \lstinline+results+ is the object returned by the estimation
function, the results of the estimation can be accessed in
\lstinline+results.data+:
\begin{itemize}
\item \lstinline+results.data.modelName+: the model name.
\item \lstinline+results.data.nparam+: the number $K$ of estimated parameters.
\item \lstinline+results.data.betaValues+: a Numpy array containing
  the estimated values of the parameters, in an arbitrary order.
\item \lstinline+results.data.betaNames+: a list containing the name
  of the estimated parameters, in the same order as the values above.
\item \lstinline+results.data.initLogLike+: the value $\mathcal{L}^i$
  is the initial log likelihood. 
\item \lstinline+results.data.betas+: a list of objects corresponding
  to the parameters. Each of these objects contains the following
  entries, which should be self explanatory. 
\begin{itemize}
\item \lstinline+beta.name+,
\item \lstinline+beta.value+,
\item \lstinline+beta.stdErr+,
\item \lstinline+beta.lb+,
\item \lstinline+beta.ub+,
\item \lstinline+beta.tTest+,
\item \lstinline+beta.pValue+,
\item \lstinline+beta.robust_stdErr+,
\item \lstinline+beta.robust_tTest+,
\item \lstinline+beta.robust_pValue+,
\item \lstinline+beta.bootstrap_stdErr+,
\item \lstinline+beta.bootstrap_tTest+,
\item \lstinline+beta.bootstrap_pValue+.
\end{itemize}
  
\item \lstinline+results.data.logLike+: the value $\mathcal{L}^*$ of
  the log likelihood at the final value of the parameters. 
\item \lstinline+results.data.g+: the gradient of the log likelihood at the final value of the parameters. 
\item \lstinline+results.data.H+: the second derivatives matrix of the log likelihood at the final value of the parameters. 
\item \lstinline+results.data.bhhh+:  the BHHH matrix \req{eq:binaryBHHH}  at the final value of the parameters. 
\item \lstinline+results.data.dataname+: the name of the database.
\item \lstinline+results.data.sampleSize+: the sample size $N$.
\item \lstinline+results.data.numberOfObservations+: the number of
  rows in the data file. If the data is not panel, it is the same as
  the sample size. 
\item \lstinline+results.data.monteCarlo+: a boolean that is True if
  the model involves Monte-Carlo simulation for the calculation of
  integrals. 
\item \lstinline+results.data.numberOfDraws+: number of draws used for
  Monte-Carlo simulation.
\item \lstinline+results.data.typesOfDraws+: type of draws used for
  Monte-Carlo simulation.
\item \lstinline+results.data.excludedData+: number of excluded data. 
\item \lstinline+results.data.dataProcessingTime+: time needed to
  process the data before estimation. 
\item \lstinline+results.data.drawsProcessingTime+: time needed to
  generate the draws for Monte-Carlo simulation. 
\item \lstinline+results.data.optimizationTime+: time used by the
  optimization algorithm. 
\item \lstinline+results.data.gradientNorm+: norm of the gradient of
  the log likelihood at the final value of the parameters. 
\item \lstinline+results.data.optimizationMessages+: message returned
  by the optimization routine. 
\item \lstinline+results.data.numberOfFunctionEval+: number of time
  the log likelihood function has been evaluated. 
\item \lstinline+results.data.numberOfIterations+: number of
  iterations of the optimization algorithm.
\item \lstinline+results.data.numberOfThreads+: number of processors
  used. 
\item \lstinline+results.data.htmlFileName+: name of the HTML file. 
\item \lstinline+results.data.pickleFileName+: name of the Pickle
  file. 
\item \lstinline+results.data.bootstrap+: a boolean that is True if
  the calculation of statistics using bootstrapping has been
  requested. 
\item \lstinline+results.data.bootstrapTime+: the time needed for
  calculating the statistics with bootstrapping, if applicable. 
\end{itemize}
In addition the robust variance-covariance matrix can be obtained
using
\begin{lstlisting}[style=nonumbers]
results.data.getRobustVarCovar()
\end{lstlisting}

If you are just interested in the estimates of the parameters, they
can be obtained as a \verb+dict+:
\begin{lstlisting}[style=nonumbers]
betas = results.getBetaValues()
for k,v in betas.items():
    print(f"{k}=\t{v:.3g}")
\end{lstlisting}

The general statistics can also be obtained as a \verb+dict+:
\begin{lstlisting}[style=nonumbers]
gs = results.getGeneralStatistics()
\end{lstlisting}


The results can also be obtained as a Pandas data frame:
\begin{lstlisting}[style=nonumbers]
pandasResults = results.getEstimatedParameters()
\end{lstlisting}
and
\begin{lstlisting}[style=nonumbers]
correlationResults = results.getCorrelationResults()
\end{lstlisting}


\bibliographystyle{dcu}
\bibliography{dca}


\clearpage 


\appendix

\section{Complete specification file}

\subsection{\lstinline$01logit.py$}
\label{sec:modelPython}
\lstinputlisting[style=numbers,basicstyle=\footnotesize]{\examplesPath/swissmetro/01logit.py}

\clearpage

   \section{Estimation of the  variance-covariance matrix}
   \label{sec:robust}
Under relatively general conditions,  the asymptotic
variance-covariance matrix of the maximum likelihood
estimates of the vector of parameters $\theta \in \R^K$ is given by the Cramer-Rao bound
\begin{equation}
  \label{eq:RaoCramer}
  -\expect\left[ \nabla^2 \L(\theta)\right]^{-1} =  \left\{-\expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right]\right\}^{-1}.
\end{equation}
The term in square brackets is the matrix of the second derivatives
of the log likelihood function with respect to the parameters
evaluated at the true parameters.  Thus the entry in the $k$\/th row and
the $\ell$\/th column is
\begin{equation}
  \label{eq:BAL4.34}
 \frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_{\ell}}.
\end{equation}

Since we do not know the actual values of the parameters at which to
evaluate the second derivatives, or the distribution of $x_{in}$ and
$x_{jn}$ over which to take their expected value, we estimate the
variance-covariance matrix by evaluating the second derivatives  at the estimated parameters
$\hat{\theta}$ and the sample distribution of $x_{in}$ and $x_{jn}$ instead of
 their true distribution. Thus we use
\begin{equation}
  \label{eq:BAL4.35}
  \expect\left[\frac{\partial^2 \L(\theta)}{\partial \theta_k \partial \theta_\ell}  \right]\approx \sum_{n=1}^N \left[\frac{\partial^2\left(y_{in}\ln P_n(i) + y_{jn} \ln P_n(j) \right)}{\partial \theta_k \partial \theta_\ell} \right]_{\theta=\hat{\theta}},
\end{equation}
as a consistent estimator of the matrix of second derivatives. 

Denote
this matrix as $\hat{A}$. Note that, from the second order optimality conditions of the optimization
problem, this matrix is negative semi-definite, which is the algebraic equivalent of the local  concavity of the
log likelihood function.
 If the maximum is unique, the matrix is negative definite, and the
 function is locally strictly concave. 




 An estimate of the Cramer-Rao
bound \req{eq:RaoCramer} is given by 
\begin{equation}
\label{eq:EstimateRaoCramer}
\widehat{\Sigma}^{\text{CR}}_{\theta} = -\hat{A}^{-1}.
\end{equation}
If  the matrix $\hat{A}$ is  negative definite then $-\hat{A}$ is invertible and the Cramer-Rao bound is positive definite. 

Another consistent estimator of the (negative of the) second
derivatives matrix can be obtained by the matrix of the cross-products of first derivatives as follows:
\begin{equation}
\label{eq:binaryBHHH}
-E\left[ \frac{\partial^2 \L(\theta)}{\partial \theta \partial \theta^T}\right] \approx  \sum_{n=1}^n \left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right)^T = \hat{B},
\end{equation}
 where
\begin{equation}
\left(\frac{\partial \ell_n(\hat{\theta})}{\partial \theta} \right) = \frac{\partial}{\partial \theta} (\log P(i_n|\C_n;\widehat{\theta}))
\end{equation}
is the gradient vector of the likelihood of observation $n$.
This approximation is employed by the BHHH algorithm, from the work by \citeasnoun{BernHallHallHaus74}. Therefore, an estimate of the variance-covariance matrix 
is given by 
\begin{equation}
\widehat{\Sigma}^{\text{BHHH}}_{\theta} =\hat{B}^{-1},
\end{equation}
 although it is rarely used. 
Instead, $\hat{B}$ is
used to derive  a third consistent estimator of the variance-covariance matrix of
the parameters, defined as
\begin{equation}
\label{eq:robustEstimator}
\widehat{\Sigma}^{\text{R}}_{\theta} = (-\hat{A})^{-1} \; \widehat{B}\; (-\hat{A})^{-1} = \widehat{\Sigma}^{\text{CR}}_{\theta} \; (\widehat{\Sigma}^{\text{BHHH}}_{\theta})^{-1} \; \widehat{\Sigma}^{\text{CR}}_{\theta}.
\end{equation}

It is
called the \emph{robust} estimator, or sometimes the \emph{sandwich}
estimator, due to the form of equation
\req{eq:robustEstimator}. \BIOGEME\ reports statistics based on  both the Cramer-Rao estimate
\req{eq:EstimateRaoCramer} and the robust estimate \req{eq:robustEstimator}.


 When the true likelihood function is maximized,  these estimators are
 asymptotically equivalent, and the Cramer-Rao bound should be
preferred (\cite{KaueCarr2001}).  When other consistent estimators are
used, the robust estimator must be used
(\cite{Whit82}). Consistent non-maximum likelihood estimators, known
as pseudo maximum likelihood estimators, are often used when the true
likelihood function is unknown or difficult to compute. In such cases,
it is often possible to obtain consistent estimators by maximizing an
objective function based on a simplified probability distribution. 


\section{Differences with \PBIOGEME}
The syntax of \PDBIOGEME\ has been designed to be as close as possible
to the syntax of \PBIOGEME. There are some differences though that we
mention in this Section.

\begin{itemize}
\item There is no need anymore to specify an iterator.
\item The \lstinline+BIOGEME_OBJECT+ and its variables
  (\lstinline+ESTIMATE+, \lstinline+PARAMETERS+, etc.) are obsolete.
\item The exclusion of data was done as follows in \PBIOGEME:
\begin{lstlisting}[style=nonumbers]
exclude = (( PURPOSE != 1 ) * (  PURPOSE   !=  3  ) +\
           ( CHOICE == 0 )) > 0
BIOGEME_OBJECT.EXCLUDE = exclude
\end{lstlisting}
It is done as follows is \PDBIOGEME:
\begin{lstlisting}[style=nonumbers]
exclude = (( PURPOSE != 1 ) * (  PURPOSE   !=  3  ) +\
           ( CHOICE == 0 )) > 0
database.remove(exclude)
\end{lstlisting}

\item For the specification of the parameters using the
  \lstinline+Beta+ function, the \PBIOGEME\ syntax is still valid here. But it is
slightly extended. In \PBIOGEME, it was mandatory to explicitly specify  a
lower and an upper bound. In \PDBIOGEME, it is now possible to specify
\lstinline+None+ if no bound is desired.  Note that, in \PBIOGEME, the
last argument of the \lstinline+Beta+ function allowed to give a text
description of the parameter. This argument can still be provided (for
compatibility reasons), but is ignored by \PDBIOGEME.
\item \lstinline+DefineVariable+: the syntax is similar to \PBIOGEME, but not identical. The function
\lstinline+DefineVariable+ requires a third argument, which is the
name of the database. This allows to work with different databases in
the same specification file.
\item The name of the output files is defined by the statement
\begin{lstlisting}[style=nonumbers]
biogeme.modelName = "01logit"
\end{lstlisting}
In \PBIOGEME, it was defined by the name of the script. In \PDBIOGEME,
as it is technically possible to define several models in the same
script, the name has to be explicitly mentioned.
\item As discussed above, the estimation results are available in a
  Python object. This object is actually saved in a file with the
  extension \lstinline+pickle+. This file can be read using the
  following statements:
\begin{lstlisting}[style=nonumbers]
import biogeme.results as res
results = res.bioResults(pickleFile=01logit.pickle')
\end{lstlisting}
and the object \lstinline+results+ is recovered exactly how it was
generated after the estimation. 
\end{itemize}

\end{document}





