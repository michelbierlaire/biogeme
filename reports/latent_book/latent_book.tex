\documentclass[12pt,a4paper]{article}

\usepackage{michel}
\usepackage[dcucite,abbr]{harvard}
\harvardparenthesis{none}\harvardyearparenthesis{round}
\usepackage{hyperref}
\usepackage{varioref}
\usepackage{longtable}
\usepackage{siunitx}
\sisetup{
  parse-numbers=false,      % Prevents automatic parsing (needed for parentheses & superscripts)
  detect-inline-weight=math,% Ensures proper formatting in tables
  tight-spacing=true        % Keeps spacing consistent
}
% Package to include code
\usepackage{listings}
\usepackage{color}
\lstset{language=Python}
\lstset{numbers=none, basicstyle=\footnotesize,
  numberstyle=\tiny,keywordstyle=\color{blue},stringstyle=\ttfamily,showstringspaces=false}
\lstset{backgroundcolor=\color[rgb]{0.95 0.95 0.95}}
\lstdefinestyle{numbers}{numbers=left, stepnumber=1,
  numberstyle=\tiny,basicstyle=\tiny, numbersep=10pt}
\lstdefinestyle{nonumbers}{numbers=none}
\lstset{
  breaklines=true,
  breakatwhitespace=true,
}

\title{Estimating hybrid choice models  with Biogeme}
\author{Michel Bierlaire \and Moshe Ben-Akiva \and Joan Walker} 
\date{\today}


\begin{document}


\begin{titlepage}
\pagestyle{empty}

\maketitle
\vspace{2cm}

\begin{center}
\small Report TRANSP-OR xxxxxx  \\ Transport and Mobility Laboratory \\ School of Architecture, Civil and Environmental Engineering \\ Ecole Polytechnique F\'ed\'erale de Lausanne \\ \verb+transp-or.epfl.ch+
\begin{center}
\textsc{Series on Biogeme}
\end{center}
\end{center}


\clearpage
\end{titlepage}

\begin{titlepage}
\tableofcontents
\end{titlepage}

The package Biogeme (\texttt{biogeme.epfl.ch}) is designed to estimate
the parameters of various models using maximum likelihood
estimation. It is particularly designed for discrete choice
models.  In this document, we present how to estimate  choice
models involving latent variables: hybrid choice models.

We assume that the reader is already familiar with discrete choice
models, and has successfully installed Biogeme. This document has
been written using Biogeme 3.3.2.



\section{Models and notations}
\label{sec:model}
The literature on discrete choice models with latent variables is vast
(\cite{walker2001extended}, \cite{ashok2002extending},
\cite{greene2003latent}, \cite{ben2002integration}, to cite just a
few). We start this document by a short introduction to the models and
the notations. 

\subsection{Structural equations}
A \emph{latent variable} is a variable that cannot be directly
observed. It is typically modeled using a \textbf{structural
  equation}, which expresses the latent variable as a function of
observed (explanatory) variables and an error term. A general form of
such a structural equation is:
\begin{equation}
\label{eq:structural}
x_{nk}^* = x^*(x_n; \psi_k) + \omega_{nk},
\end{equation}
where $n$ indexes individuals, $x_{nk}^*$ is the $k$th latent variable of interest, $x_n$ is a vector of observed explanatory variables, $\psi_k$ is a vector of parameters to be estimated, and $\omega_{nk}$ is a stochastic error term.

A common specification assumes a linear functional form   with i.i.d. normally distributed  error terms:
\begin{equation}
\label{eq:linearStructural}
 x_{nk}^* = \sum_s \psi_{sk} x_{ns} + \sigma_{\omega k} \omega_{nk},
\end{equation}
where $\omega_{nk} \sim N(0, 1)$, and $\sigma_{\omega k}$ is a scaling parameter for the error term. 

Information about latent variables is obtained indirectly through
\emph{measurements}, which are observable manifestations of the
underlying latent constructs. For example, in discrete choice models,
utility is not directly observed but is inferred from the choices
individuals make. The relationship between a latent variable and its
associated measurements is described by \textbf{measurement
  equations}. The specific form of these equations depends on the
nature of the observed measurements (e.g., continuous, or ordinal).


\subsection{Measurement equations: the continuous case}
\label{sec:continuous}

Since latent variables cannot be directly observed, analysts rely on
indirect measurements to infer their values. A common approach
involves asking respondents to rate the perceived magnitude of the
latent construct on an arbitrary scale. For example: \emph{``How would
you rate the level of pain that you are experiencing, from 0 (no pain)
to 10 (worst pain imaginable)?''}

Each such rating is referred to as an \emph{indicator}, indexed by
$\ell=1, \ldots, L_n$, and is modeled using a \textbf{measurement equation}. This
equation relates the observed indicator to the latent variables and, sometimes,
other explanatory variables:
\begin{equation}
\label{eq:continuousMeasurement}
I_{n\ell} = I_\ell(x_n, x_n^*;\lambda_\ell) + \upsilon_{n\ell}, \; \forall \ell=1, \ldots, L_n, \forall n,
\end{equation}
where $I_{n\ell}$ denotes the response provided by individual $n$ for
indicator $\ell$, $x_n^*$ is the latent variable of interest (e.g., pain
perception), $x_n$ is a vector of observed explanatory variables (such as
socio-demographic characteristics), $\lambda_\ell$ is a vector of
parameters to be estimated, and $\upsilon_{n\ell}$ is the random error term.

A common specification of the measurement function assumes linearity
and i.i.d. normally distributed errors:
\begin{equation}
\label{eq:linearMeasurement}
I_{n\ell} = \lambda_{\ell 0} + \sum_k \lambda_{\ell k}  x_{nk}^* + \sigma_{\upsilon \ell} \upsilon_{n\ell}, \quad \forall \ell,
\end{equation}
where $\lambda_{\ell k}$ are unknown parameters to be estimated, $\sigma_{\upsilon \ell}$ is an indicator-specific scale parameter, and $\upsilon_{n\ell} \sim N(0, 1)$.

If we observe a vector of continuous indicators \( I_n = (I_{n1}, \ldots, I_{nL_n}) \) for individual \( n \), the contribution to the likelihood function, \emph{conditional on the latent variables} \( x^*_{n} \), is given by the product:
\begin{equation}
  \label{eq:conditional_likelihood_continuous}
\prod_{\ell=1}^{L_n} \phi\left( \frac{I_{n\ell} - \lambda_{\ell 0} - \sum_k \lambda_{\ell k} x_{nk}^*}{\sigma_{\upsilon \ell}} \right),
\end{equation}
where \( \phi(\cdot) \) denotes the probability density function (pdf) of the standard normal distribution.

If other types of observations are available for the same individual (such as discrete choices), the corresponding components of the likelihood can be multiplied with the expression above. Once all relevant components are combined, the latent variables must be integrated out, as discussed later.

If the continuous indicators are the only data available for individual \( n \), the contribution to the unconditional likelihood becomes:
\begin{equation}
  \label{eq:likelihood_continuous}
\int_{x_n^*} \left[ \prod_{\ell=1}^{L_n} \phi\left( \frac{I_{n\ell} - \lambda_{\ell 0} - \sum_k \lambda_{\ell k} x_{nk}^*}{\sigma_{\upsilon \ell}} \right) \right] f(x_n^*) \, dx_n^*,
\end{equation}
where \( f(x_n^*) \) is the pdf of the vector of latent variables \( x_n^* \).
As this integral does not have a closed-form expression, it is approximated using Monte Carlo integration (see \cite{Bier19} for a discussion about performing Monte-Carlo integration with Biogeme).




\subsection{Measurement equation: the ordinal case}
\label{sec:likert}

Another type of indicator arises when respondents are asked to
evaluate a statement using an ordinal scale. A typical context for
this type of measurement is the use of a Likert scale
(\cite{likert1932technique}), where individuals express their degree of
agreement or disagreement with a given statement. For example:
\begin{quote}
\emph{``I believe that my own actions have an impact on the planet.''} \\
Response options: strongly agree (2), agree (1), neutral (0), disagree ($-1$), strongly disagree ($-2$).
\end{quote}


To model these types of indicators, we represent the observed
measurement as an \emph{ordered discrete variable} $I_{n\ell}$, which
takes values in a finite, ordered set $\{j_1, j_2, \ldots, j_{M_\ell}\}$. The
measurement equation involves two stages:

\paragraph{Step 1: Latent response formulation.} We first define a continuous response variable, as explained in Section~\ref{sec:continuous}, except that it happens to be unobserved (latent) in this case:
\begin{equation}
I^*_{n\ell} = I^*_\ell(x_n, x_n^*; \lambda_\ell) + \upsilon_{n\ell},
\end{equation}
where $I^*_{n\ell}$ is a continuous latent variable underlying the
reported response, $x_n^*$ is a vector of  relevant latent variables (e.g.,
environmental concern), $x_n$ is a vector of observed explanatory
variables (e.g., age, income), $\lambda$ is a vector of parameters to
be estimated, and $\upsilon_{n\ell}$ is a random error term.

\paragraph{Step 2: Discretization via thresholds.} Since $I^*_{n\ell}$ is not observed, we relate it to the reported discrete measurement $I_{n\ell}$ through a set of threshold parameters:
\begin{equation}
\label{eq:discreteMeas-b}
I_{n\ell} = \left\{
\begin{array}{ll}
j_1 & \text{if } I^*_{n\ell} < \tau_1, \\
j_2 & \text{if } \tau_1 \leq I^*_{n\ell} < \tau_2, \\
\vdots \\
j_m & \text{if } \tau_{m-1} \leq I^*_{n\ell} < \tau_m, \\
\vdots \\
j_M & \text{if } \tau_{M_\ell-1} \leq I^*_{n\ell},
\end{array}
\right.
\end{equation}
where $\tau_1, \ldots, \tau_{M_\ell-1}$ are threshold parameters to be estimated, satisfying the ordering constraint:
\begin{equation}
\label{eq:discreteMeas-c}
\tau_1 \leq \tau_2 \leq \cdots \leq \tau_{M_\ell-1}.
\end{equation}
Note that it is customary to use the same set of parameters for all
individuals $n$ and all indicators $\ell$, which explains the absence
of these indices on the parameter $\tau$.

Defining $\tau_0=-\infty$ and $\tau_{M_\ell}=+\infty$, it simplifies to
\begin{equation}
  \label{eq:prob_indicator}
I_{n\ell} = j_m  \text{ if } \tau_{m-1} \leq I^*_{n\ell} < \tau_m, \; m=1, \ldots, M_\ell. 
\end{equation}

It is often advantageous to impose a symmetric structure on the
definition of the thresholds. In addition, it is more convenient from
an estimation standpoint to parameterize the thresholds in terms of
differences and to constrain these differences to be positive. For
example, when \( M_\ell = 4 \), the thresholds can be defined as
follows:
\[
\begin{aligned}
  \tau_1 &= -\delta_1 -\delta_2, \\
  \tau_2 &= -\delta_1, \\
  \tau_3 &= \phantom{-}\delta_1, \\
  \tau_4 &= \phantom{-}\delta_1 + \delta_2,
\end{aligned}
\]
where \( \delta_1 > 0 \) and \( \delta_2 > 0 \) are the parameters to
be estimated.
This parameterization guarantees that the thresholds are strictly ordered 
and symmetrically centered around zero, which facilitates both 
identification and interpretation. 


If we consider a linear specification,
\begin{equation}
  \label{eq:measurement_latent}
I^*_{n\ell} = \lambda_{\ell 0}  + \sum_k \lambda_{\ell k}  x_{nk}^* + \sigma_{\upsilon \ell} \upsilon_{n\ell}, \quad \forall \ell,
\end{equation}
where the error term $\upsilon_{n\ell} \sim N(0,1)$,
the contribution of each indicator $\ell$ for each observation $n$ to the likelihood function, \emph{conditional on the latent variables}, is defined as follows:
\begin{equation}
  \label{eq:discreteMeas-d}
  \begin{aligned}
    \prob(I_{n\ell} = j_m| x^*_n, x_n ; \lambda_\ell, \Sigma_{\upsilon \ell})
    =& \prob(\tau_{m-1} \leq I^*_{n\ell} \leq \tau_m) \\
    =& \prob(I^*_{n\ell} \leq \tau_m) -  \prob(I^*_{n\ell} \leq \tau_{m-1}),\\
    =& \prob\left( \upsilon_{n\ell} \leq \frac{\tau_m -\lambda_{\ell 0}  - \sum_k \lambda_{\ell k}  x_{nk}^*}{\sigma_{\upsilon \ell}} \right) \\
    &-  \prob \left( \upsilon_{n\ell} \leq \frac{\tau_{m-1}- \lambda_{\ell 0}  - \sum_k \lambda_{\ell k}  x_{nk}^*}{\sigma_{\upsilon \ell}}\right), \\
    =& \Phi\left(  \frac{\tau_m -\lambda_{\ell 0}  - \sum_k \lambda_{\ell k}  x_{nk}^*}{\sigma_{\upsilon \ell}} \right) \\
    &-\Phi\left(\frac{\tau_{m-1}- \lambda_{\ell 0}  - \sum_k \lambda_{\ell k}  x_{nk}^*}{\sigma_{\upsilon \ell}}\right)
  \end{aligned}
\end{equation}
where $j_m$ is the observed category for respondent $n$ and indicator $\ell$.

This specification is known as the \emph{ordered probit model} and is
widely used for modeling ordinal responses that depend on latent
constructs.

If we observe a vector of continuous indicators \( I_n = (I_{n1}, \ldots, I_{nL_n}) \) for individual \( n \), the contribution to the likelihood function, \emph{conditional on the latent variables} \( x^*_{n} \), is given by:
\begin{equation}
\prod_{\ell=1}^{L_n} \prob(I_{n\ell} = j_m| x^*_n, x_n ; \lambda_\ell, \Sigma_{\upsilon \ell}).
\end{equation}

As in the continous case, if other types of observations are available
for the same individual (such as  choices), the corresponding
components of the likelihood can be multiplied with the expression
above. Once all relevant components are combined, the latent variables
must be integrated out, as discussed later.

If the continuous indicators are the only data available for individual \( n \), the contribution to the unconditional likelihood becomes:
\begin{equation}
\int_{x_n^*} \left[ \prod_{\ell=1}^{L_n} \prob(I_{n\ell} = j_m| x^*_n, x_n ; \lambda_\ell, \Sigma_{\upsilon \ell})
\right] f(x_n^*) \, dx_n^*,
\end{equation}
where \( f(x_n^*) \) is the pdf of the vector of latent variables \( x_n^* \).
Again, this integral is approximated using Monte-Carlo integration.


\section{Normalization and identification in latent-variable models}
\label{sec:normalization}

Models with latent variables contain parameters that are not uniquely
identified from the data unless additional restrictions are imposed.
These restrictions, referred to as \emph{normalizations}, are not
behavioral assumptions; rather, they fix the arbitrary units of
measurement (location and scale) that are inherent to latent constructs
and ordinal measurement schemes.

This section explains why normalization is required, where
non-identification arises, and how to impose a consistent and
non-redundant set of normalizations. We distinguish carefully between
normalizations related to the \emph{latent variables themselves} and
those related to the \emph{ordinal measurement models}. Although the
reference-indicator strategy is emphasized for its interpretability and
numerical stability, the underlying principles apply more generally.

\subsection{Sources of non-identification}

Latent-variable models are invariant to specific transformations of the
latent variables and associated parameters. Without normalization,
multiple parameter vectors generate exactly the same likelihood. In such
a case, estimation is ill-posed: the likelihood exhibits flat or weakly
curved directions, standard errors are unreliable, and numerical
optimization or Bayesian sampling may be unstable.

Two fundamental sources of non-identification arise at the level of the
latent variables:

\begin{itemize}
  \item \textbf{Location invariance}: the origin of a latent variable is
  arbitrary.
  \item \textbf{Scale invariance}: the unit in which a latent variable is
  measured is arbitrary.
\end{itemize}

Both must be addressed for each latent variable in the model.
Note that the need for normalization in latent-variable models is closely analogous
to the well-known identification issues in logit models and
related random utility models. In logit, utilities are latent and only
differences in utility matter. As a consequence, utilities are invariant
to the addition of a constant (location invariance) and to multiplication
by a positive scalar (scale invariance). Standard practice therefore
requires fixing one alternative-specific constant (or equivalently
normalizing utilities relative to a base alternative) and fixing the
scale of utility, typically by normalizing the variance of the error term.

Latent variables play a role analogous to latent utilities: they enter
the likelihood only through systematic components and relative
comparisons. Continuous measurement equations therefore require exactly
the same type of normalization as utility functions in logit models --- one
restriction to fix location and one to fix scale. Likewise, ordinal
measurement equations introduce additional latent constructs (latent
responses) that must be normalized in the same spirit as discrete choice
utilities defined over ordered alternatives.

\subsection{Normalization for continuous measurement equations}

Consider the linear measurement and structural equations introduced in
Section~\ref{sec:model}. If intercepts are estimated, any
shift of a latent variable can be absorbed by a compensating shift in
the measurement intercepts. Likewise, any rescaling of a latent variable
can be offset by rescaling loadings and structural parameters. As a
result, neither the location nor the scale of the latent variable is
identified from the data alone.

Therefore, for each latent variable, exactly two normalizations are
required:
\begin{itemize}
  \item one to fix its \emph{location};
  \item one to fix its \emph{scale}.
\end{itemize}

A practical and interpretable approach is the
\emph{reference-indicator strategy}. For each latent variable $k$, one
indicator $\ell(k)$ is selected as its reference indicator. Location is
fixed by setting the corresponding intercept to zero, and scale is fixed
by fixing the corresponding loading to $\pm 1$. The sign choice is a
convention that determines the orientation of the latent scale and
should be chosen to preserve semantic consistency between the latent
variable and its indicators.

Once these two constraints are imposed, remaining parameters—such as
measurement error variances—become meaningful and interpretable.

\subsection{Ordinal indicators and ordered probit measurement models}

We now consider ordinal indicators modeled using an ordered probit
specification, as introduced in Section~\ref{sec:likert}. In this case,
the observed response does not reveal the latent measurement equation
directly, but only the interval in which an underlying latent response
lies.

Compared to continuous indicators, ordered probit models introduce
\emph{additional} invariances:
\begin{itemize}
  \item a \textbf{threshold-location invariance}: adding the same
  constant to the latent response and all thresholds leaves choice
  probabilities unchanged;
  \item a \textbf{threshold-scale invariance}: multiplying the latent
  response, all thresholds, and the measurement error standard deviation
  by the same positive constant leaves probabilities unchanged.
\end{itemize}

These invariances are \emph{specific to each ordered probit measurement
equation}. Crucially, they arise \emph{independently for each distinct
set of thresholds}. As a consequence, normalization of the ordered
probit layer must be performed \emph{separately for each independent
threshold system}.

\subsection{Separation of roles: latent variables vs.\ ordinal layers}

It is essential to distinguish clearly between:
\begin{itemize}
  \item normalizations that identify the \emph{latent variables};
  \item normalizations that identify the \emph{ordinal measurement
  scales}.
\end{itemize}

The reference-indicator normalizations (intercept and loading) serve
only to fix the location and scale of the latent variables. They do
\emph{not} resolve the invariances intrinsic to the ordered probit
measurement model. Those must be addressed at the level of the ordinal
layer itself.

\subsection{Normalization procedure for ordinal indicators}

For each ordinal indicator (or group of indicators) that shares a common
set of thresholds, the following steps are required.

\paragraph{Step 1: Anchor the latent variable (once per latent variable).}
If the ordinal indicator is chosen as the reference indicator for a
latent variable, impose the same normalization as in the continuous
case: fix the intercept and one loading. This step fixes the location,
scale, and orientation of the latent variable and should be applied
\emph{once per latent variable}, not per indicator.

\paragraph{Step 2: Fix the location of the threshold system (once per
threshold set).}
Because only differences between the latent response and the thresholds
matter, the threshold system has an arbitrary origin. This must be fixed
exactly once for each independent set of thresholds. This can be done
either by fixing one threshold to zero or, when the response scale is
designed to be symmetric, by imposing symmetry around zero. The latter
approach is often preferable, as it aligns the statistical
parameterization with the semantics of Likert-type scales and reduces
dimensionality.

\paragraph{Step 3: Fix the scale of the ordered probit layer (once per
threshold set).}
Ordered probit models do not identify the scale of the latent response
relative to the threshold spacing and the measurement error variance.
Therefore, one scale normalization is required for each independent
threshold system. A standard and convenient choice is to fix the
measurement error standard deviation to one. This follows conventional
ordered probit practice and prevents threshold spacings from being
confounded with noise variance.

\subsection{Key principle: no redundancy}

Each source of invariance must be removed \emph{once, and only once}.
Over-normalization—such as fixing both threshold location and an
equivalent intercept, or fixing both loading and latent variance—does
not improve identification and may instead induce artificial parameter
correlations or numerical instability.

\subsection{Alternative normalizations and choice of parameterization}

The normalizations described above are not unique. As in discrete choice
models, several equivalent normalization strategies can be adopted,
leading to identical likelihood values and identical fitted probabilities.
The choice among them affects interpretation, numerical stability, and
the transparency of the resulting parameters, but not the model's ability
to fit the data.

For latent variables, scale can be fixed in different ways. Instead of
fixing a factor loading to $\pm 1$, one may fix the variance of the latent
variable (or of the structural disturbance) to one, or impose a
``money-metric'' normalization by fixing the coefficient of a monetary
variable to a known value. Such approaches are common in structural
discrete choice models and welfare analysis. However, when latent
variables are measured through multiple indicators, these alternatives
often lead to less transparent interpretations: the latent variable is no
longer anchored directly to an observed indicator, and factor loadings
must be interpreted relative to an abstract latent scale.

Similarly, in ordered probit measurement models, scale may in principle
be fixed by normalizing threshold spacings or by normalizing the variance
of the latent response. Fixing the measurement error variance to one is
the most common convention, as it cleanly separates threshold locations
from noise and aligns the specification with standard ordered probit
practice.

In this work, we adopt the reference-indicator strategy for latent
variables and variance normalization for ordered probit layers because
this combination offers three practical advantages. First, it yields
parameters with a direct and intuitive interpretation: the latent
variable is measured in the same units as a concrete, observed indicator.
Second, it avoids entangling scale normalization with structural
parameters, which improves numerical stability in both maximum
likelihood and Bayesian estimation. Third, it allows different ordinal
indicators --- possibly with different numbers of categories or symmetric
designs --- to be normalized independently and consistently.

Importantly, this choice reflects a modeling convention rather than a
substantive behavioral assumption. Alternative normalizations are valid
and may be preferable in other contexts, provided that each source of
invariance is addressed exactly once and that the resulting parameter
interpretation is clearly documented.

\subsection{Summary of recommended practice}

The main normalization principles are summarized in
Table~\ref{tab:normalization_summary}.

\begin{itemize}
  \item For each latent variable: fix one intercept and one loading using
  a reference indicator.
  \item For each independent ordered probit threshold system:
  \begin{itemize}
    \item fix threshold location (preferably via symmetry);
    \item fix threshold scale (e.g.\ by setting the measurement error
    standard deviation to one).
  \end{itemize}
\end{itemize}

This strategy removes all location and scale indeterminacies without
redundancy, yields stable estimation, and ensures that all parameters
retain a clear and interpretable meaning.

\begin{sidewaystable}[htbp]
\centering
\caption{Summary of normalization requirements in latent-variable and ordered probit models}
\label{tab:normalization_summary}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{p{4.5cm} p{5.0cm} p{6.0cm} p{4.5cm}}
\hline
\textbf{Model component} 
& \textbf{Source of non-identification} 
& \textbf{Normalization required} 
& \textbf{Applied how often} \\
\hline

Latent variable $x_k^*$ 
& Location invariance 
& Fix one measurement intercept (reference indicator) 
& Once per latent variable \\

Latent variable $x_k^*$ 
& Scale invariance 
& Fix one loading to $\pm 1$ (reference indicator) 
& Once per latent variable \\

\hline

Continuous measurement equation 
& None beyond latent-variable invariance 
& No additional normalization 
& --- \\

\hline

Ordinal measurement (ordered probit) 
& Threshold location invariance 
& Fix one threshold to zero \emph{or} impose symmetry 
& Once per independent threshold set \\

Ordinal measurement (ordered probit) 
& Threshold scale invariance 
& Fix measurement error scale (e.g.\ $\sigma=1$) 
& Once per independent threshold set \\

\hline

Multiple ordinal indicators 
& Independent threshold systems 
& Each threshold system normalized separately 
& Once per threshold system \\

\hline
\end{tabular}
\end{sidewaystable}

%================================================================
\section{Hybrid choice models}
\label{sec:hcm}
%================================================================

This section builds on the notation and model components introduced in
Section~\ref{sec:model}. We combine the structural equations for the
latent variables, the measurement
equations for the indicators (continuous or ordinal), and  a
discrete choice model, into two frameworks of increasing scope: the
\emph{MIMIC} model and the \emph{hybrid choice model}.

We use the same notations as in Section~\ref{sec:model}: $n$ indexes individuals, $x_n$ denotes the
observed explanatory variables, $x_n^*$ the vector of latent
variables, $I_n$ the vector of observed indicators, and
$i_n\in\mathcal C_n$ the observed choice.

%----------------------------------------------------------------
\subsection{The MIMIC model}
\label{sec:mimic}
%----------------------------------------------------------------

A \emph{Multiple Indicators Multiple Causes} (MIMIC) model is obtained by
combining:
\begin{itemize}
  \item the structural part (``multiple causes''), which explains
  each latent variable as a function of observed covariates through the
  structural equations \req{eq:linearStructural}; and
  \item the measurement part (``multiple indicators''), which
  explains each indicator as a function of the latent variables through
  measurement equations (continuous indicators: \req{eq:linearMeasurement};
  ordinal indicators: ordered probit, \req{eq:discreteMeas-d}).
\end{itemize}

The purpose of the MIMIC model is to infer latent variables from their
observable manifestations (the indicators) while simultaneously
explaining how these latent constructs vary with observed covariates.

For a given individual $n$, the contribution of the indicators to the
likelihood \emph{conditional on the latent variables} $x_n^*$
is obtained by multiplying the indicator-specific contributions:
\begin{equation}
  \label{eq:mimic_conditional_indicator_likelihood}
  L_n^{I}\!\left(I_n \mid x_n^*,x_n\right)
  \;=\;
  \prod_{\ell=1}^{L_n}
  \begin{cases}
    \text{density of Eq.~\eqref{eq:conditional_likelihood_continuous}}, &
    \text{if indicator $\ell$ is continuous},\\
    \text{probability of Eq.~\eqref{eq:discreteMeas-d}}, &
    \text{if indicator $\ell$ is ordinal}.
  \end{cases}
\end{equation}

Because $x_n^*$ is not observed, the individual likelihood
contribution integrates the conditional indicator likelihood over the
distribution of the latent variables implied by the structural equations:
\begin{equation}
  \label{eq:mimic_likelihood}
  L_n^{\text{MIMIC}}
  \;=\;
  \int_{x_n^*}
  L_n^{I}\!\left(I_n \mid x_n^*,x_n\right)\;
  f(x_n^*\mid x_n)\;
  dx_n^*,
\end{equation}
where $f(x_n^*\mid x_n)$ is the conditional
density implied by Eq.~\eqref{eq:linearStructural}.

%----------------------------------------------------------------
\subsection{Hybrid choice model (choice model with latent variables)}
\label{sec:hybrid_choice_model}
%----------------------------------------------------------------

A \emph{hybrid choice model} extends the MIMIC model by adding a discrete
choice component in which latent variables enter the systematic utilities.
The key modeling idea is that attitudes or perceptions (latent variables)
may influence choices, while being measured only indirectly through the
indicators.

Let $V_{in}(x_n,x_n^*;\beta)$ denote the
systematic utility of alternative $i$ for individual $n$. The probability of the
observed choice $i_n$ conditional on the latent variables is
\begin{equation}
  \label{eq:hcm_choice_conditional}
  P(i_n \mid x_n^*,x_n;\beta)
  \;=\;
  \frac{\exp\!\left(\mu\,V_{in}(x_n,x_n^*;\beta)\right)}
  {\sum_{j\in\mathcal C_n}\exp\!\left(\mu\,V_{jn}(x_n,x_n^*;\beta)\right)},
\end{equation}
where $\mu$ is the scale parameter of the logit model and $\beta$ is the
vector of utility parameters. Note that the logit model is adopted here for expositional convenience and because it is a widely used specification. However, the framework is fully general and can accommodate alternative discrete choice models, such as nested logit or cross-nested logit models, without any conceptual modification.



For a given individual $n$, the full observation is
$(i_n,I_n)$. Conditional on $x_n^*$, the hybrid
choice model contribution to the likelihood is the product of:
\begin{itemize}
  \item the conditional choice probability from Eq.~\eqref{eq:hcm_choice_conditional},
  \item the conditional indicator likelihood from
  Eq.~\eqref{eq:mimic_conditional_indicator_likelihood}.
\end{itemize}
That is,
\begin{equation}
  \label{eq:hcm_joint_conditional_likelihood}
  L_n\!\left(i_n,I_n \mid x_n^*,x_n\right)
  \;=\;
  P(i_n\mid x_n^*,x_n;\beta)\;
  L_n^{I}\!\left(I_n \mid x_n^*,x_n\right).
\end{equation}

Because $x_n^*$ is latent, the individual likelihood
contribution integrates \eqref{eq:hcm_joint_conditional_likelihood} over
$f(x_n^*\mid x_n)$ implied by the structural
equations \req{eq:linearStructural}:
\begin{equation}
  \label{eq:hcm_likelihood}
  L_n^{\text{HCM}}
  \;=\;
  \int_{x_n^*}
  P(i_n\mid x_n^*,x_n;\beta)\;
  L_n^{I}\!\left(I_n \mid x_n^*,x_n\right)\;
  f(x_n^*\mid x_n)\;
  dx_n^*.
\end{equation}

Let $\theta$ denote the full parameter vector, including the parameters
of the choice model, structural equations, and measurement equations (and
thresholds for ordinal indicators). The sample log-likelihood is
\begin{equation}
  \label{eq:hcm_loglikelihood}
  \begin{aligned}
  \LL(\theta) & =
  \sum_n \ln L_n^{\text{HCM}} \\
  &=
  \sum_n \ln \left[
  \int_{x_n^*}
  P(i_n\mid x_n^*,x_n;\beta)\;
  L_n^{I}\!\left(I_n \mid x_n^*,x_n\right)\;
  f(x_n^*\mid x_n)\;
  dx_n^*
  \right].
  \end{aligned}
\end{equation}

The integral in \eqref{eq:hcm_loglikelihood} typically has no closed form
and is evaluated numerically, most often by Monte-Carlo integration.

\section{A case study}
\label{sec:example}
This example focuses on the estimation of a mode choice model for
residents of Switzerland, using revealed preference data. The data
were collected as part of a research project aimed to assess the market potential
of combined mobility solutions --- particularly in urban agglomerations --- by
identifying the factors that influence individuals in their choice of
transport mode (\cite{OptimaRP2011}).

The survey was conducted between 2009 and 2010 on behalf of CarPostal,
the public transport operator of the Swiss Postal Service. Its primary
objective was to collect data on travel behavior in low-density areas,
which represent the typical service environment of CarPostal. In
addition to revealed preference data, the survey includes several
psychometric indicators, enabling the incorporation of latent
variables into the model specification.

The data file as well as its description is available on the \href{http://biogeme.epfl.ch/#data}{Biogeme webpage}. A description of the variables is also available in Appendix~\ref{sec:variables}.

We consider a  model involving two latent variables. The
first one captures a ``car-centric'' attitude. The second one captures
an ``environmental attitude''. The car-centric attitude captures the
extent to which individuals exhibit a strong preference for private
car use as their primary mode of transportation. This latent construct
reflects values such as independence, flexibility, comfort, and
perceived status associated with driving. Individuals with a high
car-centric attitude are more likely to perceive cars as the most
practical and desirable means of travel, often resisting modal shift
to public transport or active mobility.
The environmental attitude represents the degree to which individuals
value environmental protection and sustainability in their mobility
choices. It reflects concerns about issues such as climate change,
air pollution, energy consumption, and the broader environmental
impacts of transportation. Individuals with a strong environmental
attitude are more likely to favor low-emission travel options, to
support policies that reduce car use, and to accept constraints on
private mobility when these contribute to environmental goals.


\subsection{Psychometric indicators}
\label{sec:psycho}
The psychmometric indicators selected to be used in the model are the following:
\begin{description}
  \item[Envir01] Fuel price should be increased to reduce congestion and air pollution.
  \item[Envir02] More public transportation is needed, even if taxes are set to pay the additional costs.
  \item[Envir03] Ecology disadvantages minorities and small businesses.
  \item[Envir04] People and employment are more important than the environment.
  \item[Envir05] I am concerned about global warming.
  \item[Envir06] Actions and decision making are needed to limit greenhouse gas emissions.
  \item[Mobil03] I use the time of my trip in a productive way.
  \item[Mobil05] I reconsider frequently my mode choice.
  \item[Mobil08] I do not feel comfortable when I travel close to people I do not know.
  \item[Mobil09] Taking the bus helps making the city more comfortable and welcoming.
  \item[Mobil10] It is difficult to take the public transport when I travel with my children.
  \item[Mobil12] It is very important to have a beautiful car.
  \item[LifSty01] I always choose the best products regardless of price.
  \item[LifSty07] The pleasure of having something beautiful consists in showing it.
  \item[NbCar] Number of cars in the household.
\end{description}

The specification of the measurement model relies on two sets of
indicators, one for each latent variable. The \emph{car-centric}
attitude is measured using the indicators \texttt{Envir01},
\texttt{Envir02}, \texttt{Envir06}, \texttt{Mobil03}, \texttt{Mobil05},
\texttt{Mobil08}, \texttt{Mobil09}, \texttt{Mobil10}, \texttt{LifSty07},
and \texttt{NbCar}. These indicators capture aspects related to the
perceived convenience, comfort, flexibility, and social meaning of
private car use, as well as practical constraints associated with
alternative modes. The \emph{environmental} attitude is measured using
the indicators \texttt{Envir01}, \texttt{Envir02}, \texttt{Envir03},
\texttt{Envir04}, \texttt{Envir05}, \texttt{Envir06}, \texttt{Mobil12},
\texttt{LifSty01}, and \texttt{NbCar}, which reflect concerns about
environmental protection, sustainability, and the trade-offs between
environmental objectives, economic considerations, and personal
consumption preferences.

The composition of these indicator sets is not imposed \emph{a priori}
but results from a combination of theoretical considerations and an
iterative modeling process. Indicators were selected based on their
conceptual relevance to each latent construct and on empirical
performance during estimation.

The indicator \texttt{NbCar} differs in nature from the other indicators
used in the measurement model. It is not a psychometric indicator based
on attitudinal statements evaluated on a Likert scale, but an observed
household characteristic reporting the number of cars owned by the
household. This variable can take the discrete values $0$, $1$, $2$,
and $3$. Although \texttt{NbCar} does not directly measure attitudes or
perceptions, it provides valuable information about underlying latent
constructs related to mobility preferences and environmental values.
In particular, car ownership reflects long-term mobility decisions and
constraints that are strongly associated with both car-centric and
environmental attitudes. For this reason, \texttt{NbCar} is incorporated
into the model as an indicator.

\subsection{Structural equations}

For the structural equations, we use the linear specification in
Eq.~\eqref{eq:linearStructural}. The set of explanatory variables
included in each structural equation follows the specification used in
the implementation. In particular, the car-centric latent variable
$x_{n,\text{car}}^*$ is specified as a function of
\texttt{high\_education}, \texttt{top\_manager}, \texttt{employees},
\texttt{age\_30\_less}, \texttt{ScaledIncome}, and
\texttt{car\_oriented\_parents}. The environmental latent variable
$x_{n,\text{envir}}^*$ is specified as a function of \texttt{childSuburb},
\texttt{ScaledIncome}, \texttt{city\_center\_as\_kid}, \texttt{artisans},
\texttt{high\_education}, and \texttt{low\_education}. These variables are
constructed from the raw survey information during data preparation
(e.g., \texttt{ScaledIncome} is computed as \texttt{CalculatedIncome}/1000,
\texttt{age\_30\_less} is the indicator \texttt{age} $\le 30$,
\texttt{childSuburb} identifies individuals who lived in suburban areas
as children, and \texttt{car\_oriented\_parents} identifies respondents
reporting very frequent car use by parents). The final specification of
the structural equations results from a combination of behavioral
assumptions and empirical trial-and-error, balancing interpretability,
parameter stability, and overall fit.


\subsection{Measurement equations}

For each individual \( n \) and each indicator \( \ell \) described in
Section~\ref{sec:psycho}, we introduce a latent continuous response
variable, as outlined in Section~\ref{sec:likert}. This latent
response captures the unobserved propensity underlying the observed
ordinal response on a Likert scale.

For the indicators associated with the car-centric attitude, the latent response is modeled as:
\begin{equation}
  I^*_{n\ell} = \lambda_{0\ell} + \lambda_{1\ell} x^*_{n,\text{car}} + \lambda_{2\ell} \upsilon_{n\ell},
\end{equation}
where \( \lambda_{0\ell} \) is an intercept term, \( \lambda_{1\ell} \) is the loading on the latent variable \( x^*_{n,\text{car}} \), \( \lambda_{2\ell} \) scales the stochastic component, and \( \upsilon_{n\ell} \) is a random error term.

The indicator \texttt{Envir01} is selected for the normalization of
the measurement model. Individuals with a stronger car-centric
attitude are expected to be more likely to \emph{disagree} with the
corresponding statement. Accordingly, the loading \( \lambda_{1\ell}
\) is expected to be negative, and fixed to \(-1\) to establish the direction of the latent
construct. The scale parameter \( \lambda_{2\ell} \) is normalized to
1 to ensure identifiability of the model.

Similarly, for the indicators capturing the environmental attitude, we specify:
\begin{equation}
  I^*_{n\ell} = \lambda_{0\ell} + \lambda_{1\ell} x^*_{n,\text{env}} + \lambda_{2\ell} \upsilon_{n\ell},
\end{equation}
with analogous interpretation of the parameters.

The indicator \texttt{Envir02} is selected for the normalization of
this measurement model. Individuals with a stronger urban-preference
attitude are expected to be more likely to \emph{agree} with the
corresponding statement. Accordingly, the loading \( \lambda_{1\ell}
\) is expected to be positive, and fixed to 1 to establish the
direction of the latent construct. The scale parameter \(
\lambda_{2\ell} \) is normalized to 1 to ensure identifiability of the
model.

The threshold specification follows directly from the normalization and
identification principles discussed in Section~\ref{sec:normalization}
and from the ordered probit formulation introduced in
Section~\ref{sec:likert}. In particular, threshold parameterizations are
chosen so as to (i) enforce the ordering constraints, (ii) fix the
location of the ordinal response scale exactly once, and (iii) remain
consistent with the reference-indicator strategy adopted for the latent
variables.

For Likert-type indicators with five response categories, we use a
symmetric threshold parameterization centered at zero:
\[
\begin{aligned}
  \tau_1 &= -(\delta_1 + \delta_2), \\
  \tau_2 &= -\delta_1, \\
  \tau_3 &= \phantom{-}\delta_1, \\
  \tau_4 &= \phantom{-}(\delta_1 + \delta_2),
\end{aligned}
\]
where $\delta_1 > 0$ and $\delta_2 > 0$ are estimated. This
parameterization has three desirable properties. First, it guarantees
strict ordering of the thresholds by construction. Second, it fixes the
location of the threshold system by centering it at zero, thereby
removing the location indeterminacy inherent to ordered probit models.
Third, it reflects the semantic symmetry of standard Likert scales
(e.g., from ``strongly disagree'' to ``strongly agree'') while reducing
the number of free parameters. These thresholds are shared across all
Likert-type indicators, reflecting the modeling assumption that the
response categories have a comparable interpretation across statements.

The indicator \texttt{NbCar} is treated separately, as it is not a
psychometric Likert-scale indicator but an observed household
characteristic reporting the number of cars owned. Although it is used
as an indicator of the latent constructs, its response scale is
inherently asymmetric and quantitative. Since \texttt{NbCar} takes four
ordered values, three thresholds are required. For this indicator, we
adopt a non-symmetric threshold parameterization and fix the first
threshold to zero:
\[
\begin{aligned}
  \tau^{\text{NbCar}}_1 &= 0, \\
  \tau^{\text{NbCar}}_2 &= \tau^{\text{NbCar}}_1 + \delta^{\text{NbCar}}_1, \\
  \tau^{\text{NbCar}}_3 &= \tau^{\text{NbCar}}_2 + \delta^{\text{NbCar}}_2,
\end{aligned}
\]
where $\delta^{\text{NbCar}}_1 > 0$ and $\delta^{\text{NbCar}}_2 > 0$ are
estimated. Fixing $\tau^{\text{NbCar}}_1=0$ provides the required
location normalization for this indicator, while the positive
incremental parameterization ensures ordered thresholds without
imposing symmetry. This choice is fully consistent with the overall
normalization strategy: location is fixed once for the ordinal layer,
and the scale of the latent variables remains anchored through the
reference indicators.

\subsection{Implementation notes}
\label{sec:implementation_notes}

The results reported below are produced using the set of
Python specification files included in the appendix (Sections
\ref{sec:optima.py}--\ref{sec:plot_b06_hybrid_bayes.py}). These files
have been developed and tested with \texttt{Biogeme~3.3.2}. As Biogeme
evolves, minor adaptations of the syntax may be required in future
versions. The goal of the implementation is to keep the various model
variants (choice-only, MIMIC, and hybrid choice; maximum likelihood and
Bayesian estimation) consistent by relying on shared specification
components and a centralized configuration mechanism. This subsection
summarizes the role of each file and the type of specification
information it contains.

\paragraph{Data preparation (\ref{sec:optima.py}).}
The file in Section~\ref{sec:optima.py} is a standard Biogeme data
preparation script. It reads the raw data, applies the sample cleaning
rules (e.g., removal of inconsistent observations), and constructs the
derived variables used throughout the model specification (such as
scaled income, socio-demographic indicators, and other transformed
covariates). The resulting \texttt{Database} object constitutes the
common input for all estimation variants.

\paragraph{Indicator definitions and threshold conventions (\ref{sec:likert_indicators.py}).}
The file in Section~\ref{sec:likert_indicators.py} provides the complete
list of indicators used in the measurement model. For each indicator, it
stores its identifier (name), the corresponding survey statement, and
its type. In the present example, two indicator types are used:
\texttt{likert} for psychometric indicators collected on a Likert scale,
and \texttt{cars} for the discrete indicator \texttt{NbCar} (number of
cars in the household). In addition, the file defines the list of
indicator types and the associated threshold conventions. For each type,
it specifies whether the thresholds are symmetric or not, the list of
admissible response categories, and the ``neutral'' labels (if any) that
are ignored in estimation. These definitions ensure that all measurement
equations and threshold specifications are generated consistently across
the model variants.

\paragraph{Latent variable definitions (\ref{sec:latent_variables.py}).}
The file in Section~\ref{sec:latent_variables.py} defines the latent
variables used in the case study and, for each of them, the list of
explanatory variables entering its structural equation. This file
therefore contains the substantive specification choices for the
structural part of the model: the names of the latent constructs and the
observed covariates assumed to explain them.

\paragraph{Central configuration (\ref{sec:config.py}).}
To ensure that all model variants are generated from the same building
blocks, the implementation relies on a configuration object defined in
Section~\ref{sec:config.py}. This configuration determines which
components are active and how estimation is performed. It contains the
following entries:
\begin{itemize}
  \item \texttt{name}: a string identifier used to label the model run
  and its output files;
  \item \texttt{latent\_variables} (\texttt{"zero"} or \texttt{"two"}):
  whether the specification includes no latent variables or the two
  latent variables of the case study;
  \item \texttt{choice\_model} (\texttt{"yes"} or \texttt{"no"}): whether
  the discrete choice component is included (hybrid/choice-only) or
  omitted (pure MIMIC);
  \item \texttt{estimation} (\texttt{"ml"} or \texttt{"bayes"}): whether
  the model is estimated by maximum likelihood or using Bayesian
  inference;
  \item \texttt{number\_of\_bayesian\_draws\_per\_chain}: the number of
  posterior draws generated per MCMC chain (relevant when
  \texttt{estimation="bayes"});
  \item \texttt{number\_of\_monte\_carlo\_draws}: the number of Monte-Carlo
  draws used to approximate the integrals over the latent variables
  (relevant \texttt{estimation="ml"}).
\end{itemize}
This design avoids duplicating code across variants and makes the
comparison between specifications transparent.

\paragraph{MIMIC component and normalization (\ref{sec:mimic.py}).}
The file in Section~\ref{sec:mimic.py} builds the MIMIC part of the
model (structural and measurement equations) as a function of the
configuration. It is also where the reference-indicator normalization is
declared explicitly. In particular, the reference indicator used to
anchor a latent variable is identified through a normalization object of
the form \texttt{Normalization(indicator='Envir01', coefficient=-1)},
where the \texttt{coefficient} specifies the fixed loading (e.g., $-1$)
used for identification in the corresponding measurement equation. This
file therefore centralizes the measurement-structure assumptions and the
identification choices of the latent-variable system.

\paragraph{Choice model component (\ref{sec:choice_model.py}).}
The file in Section~\ref{sec:choice_model.py} contains the specification
of the discrete choice model. Depending on the configuration, the choice
model is defined either without latent variables (choice-only baseline)
or with latent variables entering the utilities (hybrid choice model).

\paragraph{Estimation control and caching of results (\ref{sec:read_or_estimate.py}).}
The file in Section~\ref{sec:read_or_estimate.py} orchestrates the
execution of the estimation in the requested mode (maximum likelihood or
Bayesian), based on the configuration. For reproducibility and
efficiency, it first checks whether estimation outputs already exist; if
so, results are read from disk rather than recomputed. Otherwise, the
file triggers a new estimation run. This file therefore handles the
``run-or-read'' logic that supports systematic experimentation with
multiple model variants.

\paragraph{Log-likelihood assembly and estimation (\ref{sec:estimate.py}).}
Finally, the file in Section~\ref{sec:estimate.py} assembles the full
model implied by the configuration and generates the corresponding
(log-)likelihood expression. This includes combining the relevant
components (choice probability, measurement likelihood, structural
density) and performing the required integration over latent variables
using Monte-Carlo simulation when appropriate. The same file then calls
the estimation routines corresponding to the selected estimation
paradigm (maximum likelihood or Bayesian). In short, it is the entry
point where the complete hybrid choice model likelihood is constructed
and estimated.

\paragraph{Estimation scripts
(\ref{sec:plot_b01_choice_only_ml.py}--\ref{sec:plot_b06_hybrid_bayes.py}).}
These are six driver scripts, each corresponding to one combination of model
scope (choice-only, MIMIC, or full hybrid choice) and estimation method
(maximum likelihood or Bayesian). Each script defines the appropriate
configuration (Section~\ref{sec:config.py}) and then relies on the
generic estimation workflow (Sections~\ref{sec:read_or_estimate.py} and
\ref{sec:estimate.py}) to either run the estimation or read existing
outputs. 

\begin{itemize}
  \item \textbf{Choice-only, maximum likelihood}
  (Section~\ref{sec:plot_b01_choice_only_ml.py}): the script
  \lstinline$plot_b01_choice_only_ml.py$ estimates the discrete choice
  model without latent variables (\lstinline$latent_variables="zero"$,
  \lstinline$choice_model="yes"$, \lstinline$estimation="ml"$). It
  provides a baseline choice specification used for comparison with
  latent-variable extensions.

  \item \textbf{MIMIC, maximum likelihood}
  (Section~\ref{sec:plot_b02_mimic_ml.py}): the script
  \lstinline$plot_b02_mimic_ml.py$ estimates the latent-variable system
  (structural and measurement equations) without the choice component
  (\lstinline$latent_variables="two"$, \lstinline$choice_model="no"$,
  \lstinline$estimation="ml"$). It focuses on how the latent constructs
  are explained by covariates and reflected in indicators.

  \item \textbf{Hybrid choice, maximum likelihood}
  (Section~\ref{sec:plot_b03_hybrid_ml.py}): the script
  \lstinline$plot_b03_hybrid_ml.py$ estimates the full hybrid choice
  model, combining the choice model with the latent-variable system
  (\lstinline$latent_variables="two"$, \lstinline$choice_model="yes"$,
  \lstinline$estimation="ml"$). The likelihood integrates the choice and
  measurement components over the latent variables.

  \item \textbf{Choice-only, Bayesian}
  (Section~\ref{sec:plot_b04_choice_only_bayes.py}): the script
  \lstinline$plot_b04_choice_only_bayes.py$ estimates the discrete choice
  model without latent variables using Bayesian inference
  (\lstinline$latent_variables="zero"$, \lstinline$choice_model="yes"$,
  \lstinline$estimation="bayes"$). It provides the Bayesian counterpart
  of the maximum-likelihood baseline.

  \item \textbf{MIMIC, Bayesian}
  (Section~\ref{sec:plot_b05_mimic_bayes.py}): the script
  \lstinline$plot_b05_mimic_bayes.py$ estimates the latent-variable
  system without the choice component using Bayesian inference
  (\lstinline$latent_variables="two"$, \lstinline$choice_model="no"$,
  \lstinline$estimation="bayes"$). It delivers posterior inference for
  the structural and measurement parameters.

  \item \textbf{Hybrid choice, Bayesian}
  (Section~\ref{sec:plot_b06_hybrid_bayes.py}): the script
  \lstinline$plot_b06_hybrid_bayes.py$ estimates the complete hybrid
  choice model using Bayesian inference
  (\lstinline$latent_variables="two"$, \lstinline$choice_model="yes"$,
  \lstinline$estimation="bayes"$). It is the most comprehensive variant
  and yields posterior distributions for both the choice parameters and
  the latent-variable system, accounting for the full joint likelihood.
\end{itemize}

All six scripts rely on the same underlying model specification files
(Sections~\ref{sec:latent_variables.py}, \ref{sec:likert_indicators.py},
\ref{sec:mimic.py}, and \ref{sec:choice_model.py}); the differences
between them arise solely from the configuration settings and the chosen
estimation paradigm.
\section{Conclusion}

Choice models with latent variables offer a powerful and flexible
framework for capturing complex behavioral mechanisms underlying
decision-making. By incorporating unobserved psychological constructs
such as attitudes, and perceptions, these models extend
the explanatory power of traditional discrete choice models. They
allow researchers to account for systematic heterogeneity in behavior
that is not directly observed in the data, thereby enhancing both the
behavioral realism and predictive performance of the models.

Despite their potential, these models are inherently more complex to
specify, estimate, and interpret. It is therefore recommended to
proceed incrementally. A practical and effective strategy is to begin
by developing and estimating the choice model and the MIMIC model
independently. This allows the analyst to ensure that both components
are correctly specified and empirically supported.

Once the separate models have been validated, the next step is to
explore their integration through sequential estimation. In this
stage, the latent variables generated from the MIMIC model are
incorporated into the utility specification of the choice model. This
provides valuable insights into how these latent constructs influence
behavior, while still maintaining manageable computational complexity.

Only after the specification has been refined and the results from the
sequential estimation are deemed satisfactory should one proceed to
the simultaneous estimation of all components. This final step --- though
computationally more demanding --- offers the benefit of statistical
efficiency by leveraging all available information jointly. It also
provides a more coherent treatment of the latent variables, since
their estimation is informed not only by the indicators, but also by
the observed choices.




\section{Description of the variables}
\label{sec:variables}

The following table describes the variables involved in the models described in this document.

\begin{longtable}{p{4cm}|p{10.5cm}}
		\hline 
		\textbf{Name} & \textbf{Description}\\
		%\tabularnewline
		\hline 
		TimePT & The duration of the loop performed in public transport (in minutes).\tabularnewline
		\hline 
		WaitingTimePT & The total waiting time in a loop performed in public transports (in minutes).\tabularnewline
		\hline 
		TimeCar & The total duration of a loop made using the car (in minutes).\tabularnewline
		\hline 
		MarginalCostPT & The total cost of a loop performed in public transports, taking into account the ownership of a seasonal ticket by the respondent. If the respondent has a ``GA'' (full Swiss season ticket), a seasonal ticket for the line or the area, this variable takes value zero. If the respondent has a half-fare travelcard, this variable corresponds to half the cost of the trip by public transport..\tabularnewline
		\hline 
		CostCarCHF & The total gas cost of a loop performed with the car in CHF.\tabularnewline
		\hline 
		TripPurpose & The main purpose of the loop: 1 =Work-related trips; 2 =Work- and leisure-related
		trips; 3 =Leisure related trips. -1 represents missing values \tabularnewline
		\hline 
		UrbRur & Binary variable, where: 1 =Rural; 2 =Urban.\tabularnewline
		\hline 
		distance\_km & Total distance performed for the loop.\tabularnewline
		\hline 
		age & Age of the respondent (in years) -1 represents missing values.\tabularnewline
		\hline 
		ResidChild & Main place of residence as a kid ($<18$), 1 is city center (large town), 2 is city center (small town), 3 is suburbs, 4 is suburban town, 5 is country side (village), 6 is countryside (isolated), -1 is for missing data and -2 if respondent didn't answer to any opinion questions. \tabularnewline
		\hline 
		NbCar & Number of cars in the household.-1 for missing value. \tabularnewline
		\hline 
		NbBicy & Number of bikes in the household. -1 for missing value.\tabularnewline
		\hline 
		HouseType & House type, 1 is individual house (or terraced house), 2 is apartment (and other types of multi-family residential), 3 is independent room (subletting). -1 for missing value.\tabularnewline
		\hline 
		Income & Net monthly income of the household in CHF. 1 is less than 2500, 2 is from 2501 to 4000, 3 is from 4001 to 6000, 4 is from 6001 to 8000, 5 is from 8001 to 10'000 and 6 is more than 10'001. -1 for missing value.\tabularnewline
		\hline 
		CalculatedIncome & Net monthly income of the household in CHF, calculated as a continuous variable. The value is the center of the interval of the corresponding incone category. \tabularnewline
		\hline
		FamilSitu & Familiar situation: 1 is single, 2 is in a couple without children, 3 is in a couple with children, 4 is single with your own children, 5 is in a colocation, 6 is with your parents and 7 is for other situations. -1 for missing values.\tabularnewline
		\hline
		SocioProfCat & To which of the following socioprofessional categories do you belong? 1 is for top managers, 2 for intellectual professions, 3 for freelancers, 4 for intermediate professions, 5 for artisans and salespersons, 6 for employees, 7 for workers and 8 for others. -1 for missing values.\tabularnewline
		\hline 
		GenAbST & Is equal to 1 if the respondent has a GA (full Swiss season ticket) and 2 if not.\tabularnewline
		\hline
		Education &Highest education achieved. As mentioned by Wikipedia in English: "The education system in Switzerland is very diverse, because the constitution of Switzerland delegates the authority for the school system mainly to the cantons. The Swiss constitution sets the foundations, namely that primary school is obligatory for every child and is free in public schools and that the confederation can run or support universities." (source: \href{http://en.wikipedia.org/wiki/Education\_in\_Switzerland}{Education in Switzerland (Wikipedia)}, accessed April 16, 2013). It is thus difficult to translate the survey that was originally in French and German. The possible answers in the survey are:
		\begin{enumerate}
			\item Unfinished compulsory education: education is compulsory in Switzerland but pupils may finish it at the legal age without succeeding the final exam.
			\item Compulsory education with diploma.
			\item Vocational education: a three or four-year period of training both in a company and following theoretical courses. Ends with a diploma called "Certificat fédéral de capacité" (i.e., ''professional baccalaureate'') (reference: \href{https://fr.wikipedia.org/wiki/Certificat\_f\%C3\%A9d\%C3\%A9ral\_de\_capacit\%C3\%A9}{Certificat fédéral de capacité (Wikipedia)} - in French).
			\item A 3-year generalist school giving access to teaching school, nursing schools, social work school, universities of applied sciences or vocational education (sometime in less than the normal number of years). It does not give access to universities in Switzerland.
			\item High school: ends with the general baccalaureate exam. The general baccalaureate gives access automatically to universities.
			\item Universities of applied sciences, teaching schools, nursing schools, social work schools: ends with a Bachelor and sometimes a Master, mostly focus on vocational training.
			\item Universities and institutes of technology: ends with an academic Bachelor and in most cases an academic Master.
			\item PhD thesis.
		\end{enumerate}\\
	\hline
		\caption{Description of variables}
		\label{tab:variables}
	\end{longtable}

\clearpage
\section{Complete specification files}

This section presents the Python implementation of the hybrid choice
model used in the case study. The following specification files have
been used for the estimation of the results presented in this chapter.
They have been developed and tested with \texttt{Biogeme~3.3.2}. It is
possible that minor adaptations of the syntax may be required for
future versions of Biogeme.

The files are organized by \emph{role} rather than by estimation
approach: data preparation and configuration, model specification
(latent variables, indicators, MIMIC and choice components), estimation
workflow, and result visualization. This structure mirrors the modeling
logic developed in the previous sections and allows the same core model
to be estimated under different assumptions (choice-only, MIMIC, or
full hybrid model; maximum likelihood or Bayesian estimation).


\subsubsection*{Data preparation and configuration}

These files define the dataset, variable transformations, and global
configuration options shared across all model variants.

\subsection{\lstinline$optima.py$}
\label{sec:optima.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/optima.py}

\subsection{\lstinline$config.py$}
\label{sec:config.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/config.py}


\subsubsection*{Latent variables and measurement structure}

The following files define the latent variables, the associated
psychometric and non-psychometric indicators, and the MIMIC component
(structural and measurement equations without choices).

\subsection{\lstinline$latent\_variables.py$}
\label{sec:latent_variables.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/latent_variables.py}

\subsection{\lstinline$likert\_indicators.py$}
\label{sec:likert_indicators.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/likert_indicators.py}

\subsection{\lstinline$mimic.py$}
\label{sec:mimic.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/mimic.py}


\subsubsection*{Choice model specification}

This file defines the discrete choice component and its interaction
with the latent variables in the hybrid choice model.

\subsection{\lstinline$choice\_model.py$}
\label{sec:choice_model.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/choice_model.py}


\subsubsection*{Estimation workflow}

These scripts orchestrate model estimation, either by reading existing
results or launching new estimation runs, and provide utilities for
batch execution.

\subsection{\lstinline$estimate.py$}
\label{sec:estimate.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/estimate.py}

\subsection{\lstinline$read\_or\_estimate.py$}
\label{sec:read_or_estimate.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/read_or_estimate.py}


\subsection{\lstinline$plot\_b01\_choice\_only\_ml.py$}
\label{sec:plot_b01_choice_only_ml.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/plot_b01_choice_only_ml.py}

\subsection{\lstinline$plot\_b02\_mimic\_ml.py$}
\label{sec:plot_b02_mimic_ml.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/plot_b02_mimic_ml.py}

\subsection{\lstinline$plot\_b03\_hybrid\_ml.py$}
\label{sec:plot_b03_hybrid_ml.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/plot_b03_hybrid_ml.py}

\subsection{\lstinline$plot\_b04\_choice\_only\_bayes.py$}
\label{sec:plot_b04_choice_only_bayes.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/plot_b04_choice_only_bayes.py}

\subsection{\lstinline$plot\_b05\_mimic\_bayes.py$}
\label{sec:plot_b05_mimic_bayes.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/plot_b05_mimic_bayes.py}

\subsection{\lstinline$plot\_b06\_hybrid\_bayes.py$}
\label{sec:plot_b06_hybrid_bayes.py}
\lstinputlisting[style=numbers]{../../docs/source/examples/hybrid_choice/plot_b06_hybrid_bayes.py}

\clearpage

\clearpage


\clearpage
\bibliographystyle{dcudoi}
\bibliography{transpor}

\end{document}


